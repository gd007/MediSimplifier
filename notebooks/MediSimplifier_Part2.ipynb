{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUNPOD ENVIRONMENT SETUP (Run once per pod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 0\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          20G  5.0G   16G  25% /\n",
      "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting typing_extensions>=4.10\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed typing_extensions-4.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (6.33.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nbmerge in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RUNPOD ENVIRONMENT SETUP (Run once per pod)\n",
    "# =============================================================================\n",
    "\n",
    "# Clear root filesystem to free space\n",
    "!rm -rf /root/.cache/huggingface /root/.cache/pip /root/.cache/torch\n",
    "!pip cache purge\n",
    "!df -h /\n",
    "\n",
    "# Remove unused packages to save space\n",
    "!pip uninstall torchaudio torchvision -y\n",
    "\n",
    "# Fix typing_extensions compatibility\n",
    "!pip install --upgrade \"typing_extensions>=4.10\" --force-reinstall\n",
    "\n",
    "# Install protobuf and sentencepiece for tokenizers\n",
    "!pip install protobuf sentencepiece --break-system-packages\n",
    "\n",
    "# Notebook merging tool\n",
    "!pip install nbmerge\n",
    "\n",
    "# PyTorch/CUDA Upgrade (H200 SXM compatibility)\n",
    "!pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu124 -q\n",
    "\n",
    "# Core data science libraries (no dependencies to avoid conflicts)\n",
    "!pip install -q --no-deps \\\n",
    "    pandas \\\n",
    "    numpy \\\n",
    "    matplotlib \\\n",
    "    seaborn\n",
    "\n",
    "# ML/NLP libraries\n",
    "!pip install -q \\\n",
    "    transformers \\\n",
    "    datasets \\\n",
    "    accelerate \\\n",
    "    peft \\\n",
    "    bitsandbytes \\\n",
    "    tqdm\n",
    "\n",
    "# Evaluation metrics\n",
    "!pip install -q \\\n",
    "    evaluate \\\n",
    "    rouge-score \\\n",
    "    bert-score \\\n",
    "    textstat \\\n",
    "    sacrebleu \\\n",
    "    git+https://github.com/feralvam/easse.git  # SARI metric (install from GitHub)\n",
    "\n",
    "# Fix scipy/numpy compatibility\n",
    "!pip install --upgrade scipy numpy --break-system-packages\n",
    "\n",
    "# ‚ö†Ô∏è RESTART KERNEL AFTER THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Dataset Formatting & Baseline Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter 5 Overview\n",
    "\n",
    "This chapter prepares **model-specific instruction datasets** from the ground truth generated in Part 1, and establishes **zero-shot baselines** for all three student models.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. **Load ground truth data** from Part 1 (labeled_splits.json)\n",
    "2. **Create model-specific instruction datasets** (ChatML for OpenBioLLM, Mistral format for others)\n",
    "3. **Define evaluation metrics** (ROUGE-L, SARI, BERTScore, Flesch-Kincaid)\n",
    "4. **Establish zero-shot baselines** for all three models\n",
    "5. **Answer research questions** RQ1 and RQ2\n",
    "\n",
    "---\n",
    "\n",
    "## Key Design Decision: Format Consistency\n",
    "\n",
    "| Stage | OpenBioLLM-8B | BioMistral / Mistral-7B |\n",
    "|-------|---------------|-------------------------|\n",
    "| Dataset Creation (5.3) | ChatML | Mistral |\n",
    "| Training (6.x) | ChatML | Mistral |\n",
    "| Baseline Eval (5.9) | ChatML | Mistral |\n",
    "| Post-FT Eval (7.x) | ChatML | Mistral |\n",
    "\n",
    "**Rationale:** Models trained and evaluated with their native format for optimal performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Research Questions Addressed\n",
    "\n",
    "| RQ | Question | Section |\n",
    "|----|----------|---------|\n",
    "| **RQ1** | Does medical pretraining help zero-shot simplification? | 5.10 |\n",
    "| **RQ2** | Which model is best at zero-shot? | 5.10 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.1: Setup & Configuration\n",
    "\n",
    "Configure environment, paths, and model definitions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch: 2.6.0+cu124\n",
      "‚úÖ CUDA available: True\n",
      "‚úÖ CUDA version: 12.4\n",
      "‚úÖ GPU: NVIDIA H200\n",
      "‚úÖ GPU Memory: 150.1 GB\n",
      "======================================================================\n",
      "SECTION 5.1: SETUP & CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üì¶ 5.1.1 Imports:\n",
      "   ‚úì All libraries imported successfully\n",
      "   ‚úì Random seed set to: 42\n",
      "   ‚úì PyTorch version: 2.6.0+cu124\n",
      "   ‚úì CUDA available: True\n",
      "   ‚úì CUDA device: NVIDIA H200\n",
      "   ‚úì CUDA memory: 150.1 GB\n",
      "\n",
      "üì¶ 5.1.2 Directory Configuration:\n",
      "   ‚úì Project root: /workspace/medisimplifier\n",
      "   ‚úì Data directory: /workspace/medisimplifier/data\n",
      "   ‚úì Results directory: /workspace/medisimplifier/results\n",
      "   ‚úì Baseline directory: /workspace/medisimplifier/results/baseline\n",
      "   ‚úì HuggingFace cache: /workspace/HFModels\n",
      "\n",
      "üì¶ 5.1.3 Model Configurations:\n",
      "   ‚úì OpenBioLLM-8B: llama3 / chatml format / Medical\n",
      "   ‚úì BioMistral-7B-DARE: mistral / mistral format / Medical\n",
      "   ‚úì Mistral-7B: mistral / mistral format / General\n",
      "\n",
      "üì¶ 5.1.4 Task Instruction (Part 2):\n",
      "   ‚úì TASK_INSTRUCTION defined (707 chars)\n",
      "\n",
      "üì¶ 5.1.5 Prompt Templates:\n",
      "   ‚úì CHATML_TEMPLATE defined (training)\n",
      "   ‚úì CHATML_INFERENCE_TEMPLATE defined (inference)\n",
      "   ‚úì MISTRAL_TEMPLATE defined (training)\n",
      "   ‚úì MISTRAL_INFERENCE_TEMPLATE defined (inference)\n",
      "\n",
      "üì¶ 5.1.6 Evaluation Configuration:\n",
      "   ‚úì Max new tokens: 512\n",
      "   ‚úì Evaluation batch size: 1\n",
      "\n",
      "üì¶ 5.1.7 Helper Functions:\n",
      "   ‚úì clear_memory()\n",
      "   ‚úì print_gpu_memory()\n",
      "   ‚úì format_inference_prompt()\n",
      "   ‚úì format_training_example()\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.1 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.1: SETUP & CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Import os module for environment variable manipulation and file system operations\n",
    "import os\n",
    "# Import Path class for object-oriented filesystem path handling\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HuggingFace Cache Configuration (MUST be set BEFORE importing transformers)\n",
    "# Redirect all caches to /workspace (persistent disk on RunPod)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define the root directory for the project on RunPod's persistent storage\n",
    "PROJECT_ROOT = Path(\"/workspace/medisimplifier\")\n",
    "# Define the directory where HuggingFace models and datasets will be cached\n",
    "HF_CACHE_DIR = Path(\"/workspace/HFModels\")\n",
    "\n",
    "# Set HF_HOME environment variable to redirect HuggingFace's main cache directory\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/HFModels\"\n",
    "# Set HF_DATASETS_CACHE to store downloaded datasets in the cache directory\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = str(HF_CACHE_DIR / \"datasets\")\n",
    "# Set HUGGINGFACE_HUB_CACHE to store model files from HuggingFace Hub\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = str(HF_CACHE_DIR / \"hub\")\n",
    "# Set PIP_CACHE_DIR to store pip packages on persistent storage\n",
    "os.environ[\"PIP_CACHE_DIR\"] = \"/workspace/pip_cache\"\n",
    "# Set TMPDIR to use persistent storage for temporary files\n",
    "os.environ[\"TMPDIR\"] = \"/workspace/tmp\"\n",
    "\n",
    "# Create the HuggingFace cache directory if it doesn't exist (with parents)\n",
    "HF_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# Create the pip cache directory if it doesn't exist\n",
    "Path(\"/workspace/pip_cache\").mkdir(parents=True, exist_ok=True)\n",
    "# Create the temporary directory if it doesn't exist\n",
    "Path(\"/workspace/tmp\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Standard Library Imports\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import sys for system-specific parameters and functions\n",
    "import sys\n",
    "# Import json for reading/writing JSON files (dataset storage)\n",
    "import json\n",
    "# Import random for reproducible random operations\n",
    "import random\n",
    "# Import warnings to suppress unnecessary warning messages\n",
    "import warnings\n",
    "# Import datetime for timestamping checkpoints and results\n",
    "from datetime import datetime\n",
    "# Import type hints for function signatures and documentation\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "# Import time for measuring execution duration\n",
    "import time\n",
    "# Import gc (garbage collector) for manual memory management\n",
    "import gc\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Science Libraries\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import numpy for numerical operations and array manipulation\n",
    "import numpy as np\n",
    "# Import pandas for tabular data manipulation and CSV operations\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Visualization Libraries\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import matplotlib.pyplot for creating charts and figures\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn for enhanced statistical visualizations\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PyTorch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Configure GPU ID for this execution\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set GPU: \"0\", \"1\", or \"2\"\n",
    "\n",
    "# Import PyTorch for deep learning operations and GPU management\n",
    "import torch\n",
    "# Import neural network module (not used directly but commonly needed)\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "# -----------------------------------------------------------------------------\n",
    "# HuggingFace Transformers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import AutoTokenizer for loading model-specific tokenizers automatically\n",
    "# Import AutoModelForCausalLM for loading causal language models (GPT-style)\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "# Import snapshot_download to pre-download models before loading\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HuggingFace Datasets\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import load_dataset for loading datasets from HuggingFace Hub\n",
    "# Import load_from_disk for loading locally saved datasets\n",
    "# Import Dataset class for creating custom datasets\n",
    "# Import DatasetDict for organizing train/val/test splits\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Evaluation Libraries\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import evaluate for loading standardized NLP metrics\n",
    "import evaluate\n",
    "# Import textstat for computing readability metrics (Flesch-Kincaid)\n",
    "import textstat\n",
    "# Import rouge_scorer as backup for ROUGE computation\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Progress Bar\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Import tqdm for displaying progress bars during long operations\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Suppress all warning messages to keep output clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Random Seed Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define global random seed for reproducibility across all experiments\n",
    "SEED = 42\n",
    "# Set Python's random module seed\n",
    "random.seed(SEED)\n",
    "# Set NumPy's random seed for array operations\n",
    "np.random.seed(SEED)\n",
    "# Set PyTorch's random seed for CPU operations\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Check if CUDA (GPU) is available for additional seed configuration\n",
    "if torch.cuda.is_available():\n",
    "    # Set random seed for all GPU devices\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Enable deterministic mode for reproducible results\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Disable benchmark mode which can cause non-determinism\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.1: SETUP & CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Print confirmation of successful imports\n",
    "print(f\"\\nüì¶ 5.1.1 Imports:\")\n",
    "print(f\"   ‚úì All libraries imported successfully\")\n",
    "print(f\"   ‚úì Random seed set to: {SEED}\")\n",
    "print(f\"   ‚úì PyTorch version: {torch.__version__}\")\n",
    "print(f\"   ‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "# Print GPU information if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   ‚úì CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   ‚úì CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Directory Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.2 Directory Configuration:\")\n",
    "\n",
    "# Define directory for storing processed datasets\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "# Define directory for storing trained model checkpoints\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "# Define directory for storing evaluation results and metrics\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "# Define directory for storing training checkpoints\n",
    "CHECKPOINTS_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "# Define directory for storing training logs\n",
    "LOGS_DIR = PROJECT_ROOT / \"logs\"\n",
    "# Define directory for storing generated figures and plots\n",
    "FIGURES_DIR = RESULTS_DIR / \"figures\"\n",
    "# Define directory for storing baseline evaluation results\n",
    "BASELINE_DIR = RESULTS_DIR / \"baseline\"\n",
    "\n",
    "# Create list of all directories that need to exist\n",
    "ALL_DIRS = [\n",
    "    PROJECT_ROOT, DATA_DIR, MODELS_DIR, RESULTS_DIR,\n",
    "    CHECKPOINTS_DIR, LOGS_DIR, FIGURES_DIR, BASELINE_DIR, HF_CACHE_DIR\n",
    "]\n",
    "\n",
    "# Create each directory if it doesn't exist (including parent directories)\n",
    "for directory in ALL_DIRS:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Print confirmation of directory paths\n",
    "print(f\"   ‚úì Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   ‚úì Data directory: {DATA_DIR}\")\n",
    "print(f\"   ‚úì Results directory: {RESULTS_DIR}\")\n",
    "print(f\"   ‚úì Baseline directory: {BASELINE_DIR}\")\n",
    "print(f\"   ‚úì HuggingFace cache: {HF_CACHE_DIR}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Model Configurations\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.3 Model Configurations:\")\n",
    "\n",
    "# Define configuration dictionary for all three student models\n",
    "# Each model has: HuggingFace path, architecture, prompt format, type, LoRA targets, parameter count\n",
    "STUDENT_MODELS = {\n",
    "    # OpenBioLLM-8B: Medical LLM based on Llama3 architecture, uses ChatML format\n",
    "    \"OpenBioLLM-8B\": {\n",
    "        \"path\": \"aaditya/Llama3-OpenBioLLM-8B\",  # HuggingFace model path\n",
    "        \"architecture\": \"llama3\",  # Base architecture type\n",
    "        \"prompt_format\": \"chatml\",  # Prompt template format to use\n",
    "        \"type\": \"Medical\",  # Model domain type for RQ analysis\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],  # LoRA target modules\n",
    "        \"parameters\": \"8B\",  # Model parameter count\n",
    "    },\n",
    "    # BioMistral-7B-DARE: Medical LLM based on Mistral architecture\n",
    "    \"BioMistral-7B-DARE\": {\n",
    "        \"path\": \"BioMistral/BioMistral-7B-DARE\",  # HuggingFace model path\n",
    "        \"architecture\": \"mistral\",  # Base architecture type\n",
    "        \"prompt_format\": \"mistral\",  # Prompt template format to use\n",
    "        \"type\": \"Medical\",  # Model domain type for RQ analysis\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],  # LoRA target modules\n",
    "        \"parameters\": \"7B\",  # Model parameter count\n",
    "    },\n",
    "    # Mistral-7B: General-purpose LLM (control/baseline for medical comparison)\n",
    "    \"Mistral-7B\": {\n",
    "        \"path\": \"mistralai/Mistral-7B-Instruct-v0.2\",  # HuggingFace model path\n",
    "        \"architecture\": \"mistral\",  # Base architecture type\n",
    "        \"prompt_format\": \"mistral\",  # Prompt template format to use\n",
    "        \"type\": \"General\",  # Model domain type for RQ analysis\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],  # LoRA target modules\n",
    "        \"parameters\": \"7B\",  # Model parameter count\n",
    "    },\n",
    "}\n",
    "\n",
    "# Print configuration summary for each model\n",
    "for name, config in STUDENT_MODELS.items():\n",
    "    print(f\"   ‚úì {name}: {config['architecture']} / {config['prompt_format']} format / {config['type']}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TASK_INSTRUCTION (Part 2 Only - Training & Inference)\n",
    "# Note: SIMPLIFICATION_INSTRUCTION is Part 1 only (Claude API ground truth)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.4 Task Instruction (Part 2):\")\n",
    "\n",
    "# Define the task instruction prompt used for training and inference\n",
    "# This is the same instruction given to student models during training and evaluation\n",
    "# Note: Different from SIMPLIFICATION_INSTRUCTION used in Part 1 for Claude API\n",
    "TASK_INSTRUCTION = \"\"\"Simplify the following medical discharge summary in plain language for patients with no medical background.\n",
    "Guidelines:\n",
    "- Replace medical jargon with everyday words (e.g., \"hypertension\" ‚Üí \"high blood pressure\")\n",
    "- Keep all important information (diagnoses, medications, follow-up instructions)\n",
    "- Use short, clear sentences (aim for 15-20 words per sentence)\n",
    "- Aim for a 6th-grade reading level\n",
    "- Maintain the same structure as the original\n",
    "- Do not add or omit information\n",
    "- Keep the same patient reference style (e.g., \"The patient\" stays \"The patient\", not \"You\")\n",
    "- Output plain text only (no markdown, no bold, no headers, no bullet points)\n",
    "- Do not include empty lines or separator characters like \"---\\\"\"\"\"\n",
    "\n",
    "# Print confirmation of instruction definition\n",
    "print(f\"   ‚úì TASK_INSTRUCTION defined ({len(TASK_INSTRUCTION)} chars)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Prompt Templates (Model-Specific)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.5 Prompt Templates:\")\n",
    "\n",
    "# ChatML Training Template for OpenBioLLM-8B\n",
    "# Format: <|im_start|>role\\ncontent<|im_end|>\n",
    "# Used during fine-tuning to format input-output pairs\n",
    "# Includes system message to properly guide model behavior\n",
    "CHATML_TEMPLATE = \"\"\"<|im_start|>system\n",
    "You are a helpful medical assistant that simplifies complex medical text for patients.<|im_end|>\n",
    "<|im_start|>user\n",
    "{instruction}\n",
    "\n",
    "{input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{output}<|im_end|>\"\"\"\n",
    "\n",
    "# ChatML Inference Template for OpenBioLLM-8B\n",
    "# Same as training but without the output (model generates it)\n",
    "# Includes system message to properly guide model behavior\n",
    "CHATML_INFERENCE_TEMPLATE = \"\"\"<|im_start|>system\n",
    "You are a helpful medical assistant that simplifies complex medical text for patients.<|im_end|>\n",
    "<|im_start|>user\n",
    "{instruction}\n",
    "\n",
    "{input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# Mistral Training Template for BioMistral and Mistral-7B\n",
    "# Format: <<SYS>> system message <</SYS>> [INST] instruction input [/INST]output\n",
    "# Used during fine-tuning to format input-output pairs\n",
    "# Includes system message to properly guide model behavior\n",
    "MISTRAL_TEMPLATE = \"\"\"[INST] <<SYS>>\n",
    "You are a helpful medical assistant that simplifies complex medical text for patients.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction}\n",
    "\n",
    "{input} [/INST]{output}\"\"\"\n",
    "\n",
    "# Mistral Inference Template for BioMistral and Mistral-7B\n",
    "# Same as training but without the output (model generates it)\n",
    "# Includes system message to properly guide model behavior\n",
    "MISTRAL_INFERENCE_TEMPLATE = \"\"\"[INST] <<SYS>>\n",
    "You are a helpful medical assistant that simplifies complex medical text for patients.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction}\n",
    "\n",
    "{input} [/INST]\"\"\"\n",
    "\n",
    "# Print confirmation of template definitions\n",
    "print(f\"   ‚úì CHATML_TEMPLATE defined (training)\")\n",
    "print(f\"   ‚úì CHATML_INFERENCE_TEMPLATE defined (inference)\")\n",
    "print(f\"   ‚úì MISTRAL_TEMPLATE defined (training)\")\n",
    "print(f\"   ‚úì MISTRAL_INFERENCE_TEMPLATE defined (inference)\")\n",
    "\n",
    "# Create mapping from format name to training template\n",
    "# Used by format_training_example() to select correct template\n",
    "TRAINING_TEMPLATES = {\n",
    "    \"chatml\": CHATML_TEMPLATE,  # OpenBioLLM-8B uses ChatML\n",
    "    \"mistral\": MISTRAL_TEMPLATE,  # BioMistral and Mistral-7B use Mistral format\n",
    "}\n",
    "\n",
    "# Create mapping from format name to inference template\n",
    "# Used by format_inference_prompt() to select correct template\n",
    "INFERENCE_TEMPLATES = {\n",
    "    \"chatml\": CHATML_INFERENCE_TEMPLATE,  # OpenBioLLM-8B uses ChatML\n",
    "    \"mistral\": MISTRAL_INFERENCE_TEMPLATE,  # BioMistral and Mistral-7B use Mistral format\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Evaluation Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.6 Evaluation Configuration:\")\n",
    "\n",
    "# Maximum number of new tokens to generate during inference\n",
    "# 512 is sufficient for simplified discharge summaries\n",
    "MAX_NEW_TOKENS = 512\n",
    "# Batch size for evaluation (1 for sequential generation to avoid OOM)\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "# Print configuration values\n",
    "print(f\"   ‚úì Max new tokens: {MAX_NEW_TOKENS}\")\n",
    "print(f\"   ‚úì Evaluation batch size: {EVAL_BATCH_SIZE}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ 5.1.7 Helper Functions:\")\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"\n",
    "    Clear GPU memory to prevent OOM errors when loading multiple models.\n",
    "    Should be called after deleting model objects.\n",
    "    \"\"\"\n",
    "    # Run Python garbage collector to free unreferenced objects\n",
    "    gc.collect()\n",
    "    # Check if CUDA is available before attempting GPU operations\n",
    "    if torch.cuda.is_available():\n",
    "        # Empty the CUDA cache to free GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        # Synchronize CUDA operations to ensure memory is freed\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def print_gpu_memory():\n",
    "    \"\"\"\n",
    "    Print current GPU memory usage for monitoring.\n",
    "    Useful for debugging OOM issues during training/inference.\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available before attempting GPU operations\n",
    "    if torch.cuda.is_available():\n",
    "        # Get currently allocated GPU memory in bytes, convert to GB\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        # Get reserved GPU memory (includes fragmentation) in bytes, convert to GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        # Print formatted memory usage\n",
    "        print(f\"   GPU Memory: {allocated:.1f}GB allocated, {reserved:.1f}GB reserved\")\n",
    "\n",
    "def format_inference_prompt(instruction: str, input_text: str, prompt_format: str) -> str:\n",
    "    \"\"\"\n",
    "    Format a prompt for inference using the model-specific template.\n",
    "    \n",
    "    Args:\n",
    "        instruction: The task instruction (TASK_INSTRUCTION)\n",
    "        input_text: The complex medical text to simplify\n",
    "        prompt_format: Either 'chatml' or 'mistral'\n",
    "    \n",
    "    Returns:\n",
    "        Formatted prompt string ready for tokenization\n",
    "    \"\"\"\n",
    "    # Look up the appropriate inference template based on format\n",
    "    template = INFERENCE_TEMPLATES[prompt_format]\n",
    "    # Fill in the template placeholders with actual values\n",
    "    return template.format(instruction=instruction, input=input_text)\n",
    "\n",
    "def format_training_example(instruction: str, input_text: str, output: str, prompt_format: str) -> str:\n",
    "    \"\"\"\n",
    "    Format a training example using the model-specific template.\n",
    "    \n",
    "    Args:\n",
    "        instruction: The task instruction (TASK_INSTRUCTION)\n",
    "        input_text: The complex medical text (input)\n",
    "        output: The simplified text (target output)\n",
    "        prompt_format: Either 'chatml' or 'mistral'\n",
    "    \n",
    "    Returns:\n",
    "        Formatted training example string with input and output\n",
    "    \"\"\"\n",
    "    # Look up the appropriate training template based on format\n",
    "    template = TRAINING_TEMPLATES[prompt_format]\n",
    "    # Fill in the template placeholders with actual values\n",
    "    return template.format(instruction=instruction, input=input_text, output=output)\n",
    "\n",
    "# Print confirmation of helper function definitions\n",
    "print(f\"   ‚úì clear_memory()\")\n",
    "print(f\"   ‚úì print_gpu_memory()\")\n",
    "print(f\"   ‚úì format_inference_prompt()\")\n",
    "print(f\"   ‚úì format_training_example()\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.1 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.2: Load Ground Truth Data (from Part 1)\n",
    "\n",
    "Load the labeled splits generated in Part 1 containing (complex_text, simplified_text) pairs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.2: LOAD GROUND TRUTH DATA\n",
      "======================================================================\n",
      "\n",
      "üìÇ Loading ground truth from: /workspace/medisimplifier/data/labeled_splits.json\n",
      "\n",
      "üìä Ground Truth Statistics:\n",
      "   ‚úì Train samples: 7,999\n",
      "   ‚úì Validation samples: 999\n",
      "   ‚úì Test samples: 1,001\n",
      "   ‚úì Total samples: 9,999\n",
      "\n",
      "üìã Sample Structure:\n",
      "   Keys: ['split', 'index', 'sample_key', 'complex_text', 'simplified_text', 'input_tokens', 'output_tokens']\n",
      "   Complex text length: 1401 chars\n",
      "   Simplified text length: 1577 chars\n",
      "\n",
      "‚úÖ Ground truth data loaded and normalized\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.2 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.2: LOAD GROUND TRUTH DATA (FROM PART 1)\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.2: LOAD GROUND TRUTH DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define path to the labeled splits JSON file created in Part 1\n",
    "# This file contains train/val/test splits with Claude-generated ground truth\n",
    "LABELED_SPLITS_PATH = DATA_DIR / \"labeled_splits.json\"\n",
    "\n",
    "# Print the path being loaded\n",
    "print(f\"\\nüìÇ Loading ground truth from: {LABELED_SPLITS_PATH}\")\n",
    "\n",
    "# Check if the ground truth file exists, raise error if not\n",
    "if not LABELED_SPLITS_PATH.exists():\n",
    "    # Provide helpful error message with instructions\n",
    "    raise FileNotFoundError(\n",
    "        f\"Ground truth file not found at {LABELED_SPLITS_PATH}. \"\n",
    "        f\"Please run Part 1 first or upload the labeled_splits.json file.\"\n",
    "    )\n",
    "\n",
    "# Open and load the JSON file containing labeled splits\n",
    "with open(LABELED_SPLITS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    # Parse JSON content into Python dictionary\n",
    "    labeled_splits = json.load(f)\n",
    "\n",
    "# Extract training data list from the labeled splits dictionary\n",
    "train_data = labeled_splits[\"train\"]\n",
    "# Extract validation data list from the labeled splits dictionary\n",
    "val_data = labeled_splits[\"validation\"]\n",
    "# Extract test data list from the labeled splits dictionary\n",
    "test_data = labeled_splits[\"test\"]\n",
    "\n",
    "# Print statistics about loaded data\n",
    "print(f\"\\nüìä Ground Truth Statistics:\")\n",
    "print(f\"   ‚úì Train samples: {len(train_data):,}\")\n",
    "print(f\"   ‚úì Validation samples: {len(val_data):,}\")\n",
    "print(f\"   ‚úì Test samples: {len(test_data):,}\")\n",
    "# Calculate and print total sample count\n",
    "print(f\"   ‚úì Total samples: {len(train_data) + len(val_data) + len(test_data):,}\")\n",
    "\n",
    "# Get first sample to verify data structure\n",
    "sample = train_data[0]\n",
    "# Print sample structure information\n",
    "print(f\"\\nüìã Sample Structure:\")\n",
    "# Print the keys present in each sample dictionary\n",
    "print(f\"   Keys: {list(sample.keys())}\")\n",
    "# Print length of complex text (input), handling both key naming conventions\n",
    "print(f\"   Complex text length: {len(sample.get('complex_text', sample.get('input', '')))} chars\")\n",
    "# Print length of simplified text (output), handling both key naming conventions\n",
    "print(f\"   Simplified text length: {len(sample.get('simplified_text', sample.get('output', '')))} chars\")\n",
    "\n",
    "def normalize_sample(sample: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Normalize sample field names for consistency across the codebase.\n",
    "    Part 1 may use 'input'/'output' while Part 2 uses 'complex_text'/'simplified_text'.\n",
    "    \n",
    "    Args:\n",
    "        sample: Dictionary with either naming convention\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with standardized 'complex_text' and 'simplified_text' keys\n",
    "    \"\"\"\n",
    "    # Create normalized dictionary with consistent key names\n",
    "    return {\n",
    "        # Try 'complex_text' first, fall back to 'input' if not found\n",
    "        \"complex_text\": sample.get(\"complex_text\", sample.get(\"input\", \"\")),\n",
    "        # Try 'simplified_text' first, fall back to 'output' if not found\n",
    "        \"simplified_text\": sample.get(\"simplified_text\", sample.get(\"output\", \"\")),\n",
    "    }\n",
    "\n",
    "# Apply normalization to all training samples using list comprehension\n",
    "train_data = [normalize_sample(s) for s in train_data]\n",
    "# Apply normalization to all validation samples\n",
    "val_data = [normalize_sample(s) for s in val_data]\n",
    "# Apply normalization to all test samples\n",
    "test_data = [normalize_sample(s) for s in test_data]\n",
    "\n",
    "# Print confirmation of successful normalization\n",
    "print(f\"\\n‚úÖ Ground truth data loaded and normalized\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.2 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.3: Create Instruction Datasets (Model-Specific)\n",
    "\n",
    "Create model-specific instruction datasets using:\n",
    "- **ChatML format** for OpenBioLLM-8B\n",
    "- **Mistral format** for BioMistral-7B-DARE and Mistral-7B\n",
    "\n",
    "All datasets use `TASK_INSTRUCTION` (not `SIMPLIFICATION_INSTRUCTION` which is Part 1 only).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.3: CREATE INSTRUCTION DATASETS (MODEL-SPECIFIC)\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.3: CREATE INSTRUCTION DATASETS (MODEL-SPECIFIC)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def create_instruction_dataset(\n",
    "    data: List[Dict],\n",
    "    prompt_format: str,\n",
    "    split_name: str\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    Create a HuggingFace Dataset with model-specific formatting.\n",
    "    \n",
    "    This function takes raw data samples and formats them according to\n",
    "    the specified prompt format (ChatML or Mistral) for training.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries with 'complex_text' and 'simplified_text' keys\n",
    "        prompt_format: Either 'chatml' (OpenBioLLM) or 'mistral' (BioMistral, Mistral-7B)\n",
    "        split_name: Name of the split ('train', 'validation', or 'test') for logging\n",
    "    \n",
    "    Returns:\n",
    "        HuggingFace Dataset with formatted examples ready for training\n",
    "    \"\"\"\n",
    "    # Initialize empty list to store formatted examples\n",
    "    formatted_examples = []\n",
    "    \n",
    "    # Iterate through each sample with progress bar\n",
    "    for sample in tqdm(data, desc=f\"Formatting {split_name} ({prompt_format})\", leave=False):\n",
    "        # Extract complex text (input) from sample\n",
    "        complex_text = sample[\"complex_text\"]\n",
    "        # Extract simplified text (target output) from sample\n",
    "        simplified_text = sample[\"simplified_text\"]\n",
    "        \n",
    "        # Create formatted text using model-specific template\n",
    "        # This combines instruction, input, and output into the correct format\n",
    "        formatted_text = format_training_example(\n",
    "            instruction=TASK_INSTRUCTION,  # Use Part 2 task instruction\n",
    "            input_text=complex_text,  # Complex medical text\n",
    "            output=simplified_text,  # Claude-generated simplified text\n",
    "            prompt_format=prompt_format  # 'chatml' or 'mistral'\n",
    "        )\n",
    "        \n",
    "        # Create example dictionary with all relevant fields\n",
    "        formatted_examples.append({\n",
    "            \"instruction\": TASK_INSTRUCTION,  # Store instruction separately\n",
    "            \"input\": complex_text,  # Store input separately\n",
    "            \"output\": simplified_text,  # Store output separately\n",
    "            \"text\": formatted_text,  # Pre-formatted text for training\n",
    "            \"prompt_format\": prompt_format,  # Track which format was used\n",
    "        })\n",
    "    \n",
    "    # Convert list of dictionaries to HuggingFace Dataset object\n",
    "    return Dataset.from_list(formatted_examples)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create ChatML Dataset (for OpenBioLLM-8B)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ Creating ChatML Dataset (OpenBioLLM-8B):\")\n",
    "\n",
    "# Create ChatML-formatted training dataset\n",
    "chatml_train = create_instruction_dataset(train_data, \"chatml\", \"train\")\n",
    "# Create ChatML-formatted validation dataset\n",
    "chatml_val = create_instruction_dataset(val_data, \"chatml\", \"validation\")\n",
    "# Create ChatML-formatted test dataset\n",
    "chatml_test = create_instruction_dataset(test_data, \"chatml\", \"test\")\n",
    "\n",
    "# Combine all splits into a DatasetDict for organized access\n",
    "chatml_dataset = DatasetDict({\n",
    "    \"train\": chatml_train,  # Training split\n",
    "    \"validation\": chatml_val,  # Validation split for hyperparameter tuning\n",
    "    \"test\": chatml_test,  # Test split for final evaluation\n",
    "})\n",
    "\n",
    "# Print sample counts for each split\n",
    "print(f\"   ‚úì Train: {len(chatml_train):,} samples\")\n",
    "print(f\"   ‚úì Validation: {len(chatml_val):,} samples\")\n",
    "print(f\"   ‚úì Test: {len(chatml_test):,} samples\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create Mistral Dataset (for BioMistral-7B-DARE and Mistral-7B)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print subsection header\n",
    "print(f\"\\nüì¶ Creating Mistral Dataset (BioMistral, Mistral-7B):\")\n",
    "\n",
    "# Create Mistral-formatted training dataset\n",
    "mistral_train = create_instruction_dataset(train_data, \"mistral\", \"train\")\n",
    "# Create Mistral-formatted validation dataset\n",
    "mistral_val = create_instruction_dataset(val_data, \"mistral\", \"validation\")\n",
    "# Create Mistral-formatted test dataset\n",
    "mistral_test = create_instruction_dataset(test_data, \"mistral\", \"test\")\n",
    "\n",
    "# Combine all splits into a DatasetDict for organized access\n",
    "mistral_dataset = DatasetDict({\n",
    "    \"train\": mistral_train,  # Training split\n",
    "    \"validation\": mistral_val,  # Validation split for hyperparameter tuning\n",
    "    \"test\": mistral_test,  # Test split for final evaluation\n",
    "})\n",
    "\n",
    "# Print sample counts for each split\n",
    "print(f\"   ‚úì Train: {len(mistral_train):,} samples\")\n",
    "print(f\"   ‚úì Validation: {len(mistral_val):,} samples\")\n",
    "print(f\"   ‚úì Test: {len(mistral_test):,} samples\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Verify Format Samples\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print verification header\n",
    "print(f\"\\nüìã Sample Verification:\")\n",
    "\n",
    "# Print first 500 characters of a ChatML-formatted sample for visual verification\n",
    "print(f\"\\n--- ChatML Format Sample (first 500 chars) ---\")\n",
    "print(chatml_train[0][\"text\"][:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Print first 500 characters of a Mistral-formatted sample for visual verification\n",
    "print(f\"\\n--- Mistral Format Sample (first 500 chars) ---\")\n",
    "print(mistral_train[0][\"text\"][:500])\n",
    "print(\"...\")\n",
    "\n",
    "# Store datasets in a dictionary for easy access by format name\n",
    "# Used in Chapter 6 for training the appropriate models\n",
    "INSTRUCTION_DATASETS = {\n",
    "    \"chatml\": chatml_dataset,  # For OpenBioLLM-8B\n",
    "    \"mistral\": mistral_dataset,  # For BioMistral and Mistral-7B\n",
    "}\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.3 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.4: Save Instruction Datasets\n",
    "\n",
    "Save model-specific instruction datasets to disk for use in Chapter 6.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.4: SAVE INSTRUCTION DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.4: SAVE INSTRUCTION DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define root directory for instruction datasets\n",
    "INSTRUCTION_DATASET_DIR = DATA_DIR / \"instruction_dataset\"\n",
    "# Create the directory if it doesn't exist\n",
    "INSTRUCTION_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define path for ChatML-formatted dataset\n",
    "chatml_path = INSTRUCTION_DATASET_DIR / \"chatml\"\n",
    "# Save ChatML dataset to disk using HuggingFace's efficient Arrow format\n",
    "chatml_dataset.save_to_disk(str(chatml_path))\n",
    "# Print confirmation of save location\n",
    "print(f\"\\nüìÅ Saved ChatML dataset to: {chatml_path}\")\n",
    "\n",
    "# Define path for Mistral-formatted dataset\n",
    "mistral_path = INSTRUCTION_DATASET_DIR / \"mistral\"\n",
    "# Save Mistral dataset to disk using HuggingFace's efficient Arrow format\n",
    "mistral_dataset.save_to_disk(str(mistral_path))\n",
    "# Print confirmation of save location\n",
    "print(f\"üìÅ Saved Mistral dataset to: {mistral_path}\")\n",
    "\n",
    "# Create metadata dictionary documenting the saved datasets\n",
    "dataset_info = {\n",
    "    \"created_at\": datetime.now().isoformat(),  # Timestamp of creation\n",
    "    \"formats\": [\"chatml\", \"mistral\"],  # Available format types\n",
    "    \"splits\": [\"train\", \"validation\", \"test\"],  # Available data splits\n",
    "    \"samples\": {  # Sample counts per split\n",
    "        \"train\": len(train_data),\n",
    "        \"validation\": len(val_data),\n",
    "        \"test\": len(test_data),\n",
    "    },\n",
    "    \"task_instruction_length\": len(TASK_INSTRUCTION),  # Instruction length for reference\n",
    "    \"model_format_mapping\": {  # Document which model uses which format\n",
    "        \"OpenBioLLM-8B\": \"chatml\",\n",
    "        \"BioMistral-7B-DARE\": \"mistral\",\n",
    "        \"Mistral-7B\": \"mistral\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define path for dataset metadata JSON file\n",
    "info_path = INSTRUCTION_DATASET_DIR / \"dataset_info.json\"\n",
    "# Save metadata to JSON file\n",
    "with open(info_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dataset_info, f, indent=2)  # Pretty-print with 2-space indent\n",
    "# Print confirmation of metadata save\n",
    "print(f\"üìÅ Saved dataset info to: {info_path}\")\n",
    "\n",
    "# Print summary of saved datasets\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "# Iterate through each format and print split counts\n",
    "for fmt, ds in INSTRUCTION_DATASETS.items():\n",
    "    print(f\"   {fmt}: {len(ds['train']):,} train, {len(ds['validation']):,} val, {len(ds['test']):,} test\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.4 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.5: Load Test Data\n",
    "\n",
    "Prepare test data for baseline evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.5: LOAD TEST DATA\n",
      "======================================================================\n",
      "\n",
      "üìä Test Data for Baseline Evaluation:\n",
      "   ‚úì Total test samples: 1,001\n",
      "   ‚úì Test samples prepared with references\n",
      "\n",
      "üìä Reference (Ground Truth) Statistics:\n",
      "   ‚úì FK Grade Mean: 7.23\n",
      "   ‚úì FK Grade Std: 1.31\n",
      "   ‚úì FK Grade Range: [3.43, 16.27]\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.5 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.5: LOAD TEST DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.5: LOAD TEST DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Note: Test data was already loaded in Section 5.2\n",
    "# This section prepares it specifically for baseline evaluation\n",
    "\n",
    "# Print test data statistics\n",
    "print(f\"\\nüìä Test Data for Baseline Evaluation:\")\n",
    "print(f\"   ‚úì Total test samples: {len(test_data):,}\")\n",
    "\n",
    "# Create list of test samples with indices for tracking\n",
    "# Each sample includes: index, complex text (input), and reference (ground truth)\n",
    "test_samples = []\n",
    "# Iterate through test data with enumeration for indexing\n",
    "for i, sample in enumerate(test_data):\n",
    "    test_samples.append({\n",
    "        \"idx\": i,  # Index for tracking and reference\n",
    "        \"complex_text\": sample[\"complex_text\"],  # Input to simplify\n",
    "        \"reference\": sample[\"simplified_text\"],  # Ground truth (Claude output)\n",
    "    })\n",
    "\n",
    "# Print confirmation of preparation\n",
    "print(f\"   ‚úì Test samples prepared with references\")\n",
    "\n",
    "# Compute Flesch-Kincaid grade level for all reference texts\n",
    "# This establishes the target reading level from Claude's outputs\n",
    "reference_fk_grades = [\n",
    "    textstat.flesch_kincaid_grade(sample[\"reference\"])  # Compute FK grade\n",
    "    for sample in test_samples  # For each test sample\n",
    "]\n",
    "# Calculate mean FK grade across all references\n",
    "reference_fk_mean = np.mean(reference_fk_grades)\n",
    "# Calculate standard deviation of FK grades\n",
    "reference_fk_std = np.std(reference_fk_grades)\n",
    "\n",
    "# Print reference statistics for comparison with model outputs\n",
    "print(f\"\\nüìä Reference (Ground Truth) Statistics:\")\n",
    "print(f\"   ‚úì FK Grade Mean: {reference_fk_mean:.2f}\")\n",
    "print(f\"   ‚úì FK Grade Std: {reference_fk_std:.2f}\")\n",
    "print(f\"   ‚úì FK Grade Range: [{min(reference_fk_grades):.2f}, {max(reference_fk_grades):.2f}]\")\n",
    "\n",
    "# Store reference statistics in a dictionary for later use\n",
    "# Used in baseline comparison and research question analysis\n",
    "REFERENCE_STATS = {\n",
    "    \"fk_mean\": reference_fk_mean,  # Mean Flesch-Kincaid grade\n",
    "    \"fk_std\": reference_fk_std,  # Standard deviation\n",
    "    \"fk_min\": min(reference_fk_grades),  # Minimum grade level\n",
    "    \"fk_max\": max(reference_fk_grades),  # Maximum grade level\n",
    "    \"n_samples\": len(test_samples),  # Total sample count\n",
    "}\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.5 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.6: Define Evaluation Metrics\n",
    "\n",
    "Define the evaluation metrics:\n",
    "- **ROUGE-L**: Longest common subsequence overlap\n",
    "- **SARI**: Simplification quality (add, keep, delete operations)\n",
    "- **BERTScore**: Semantic similarity using BERT embeddings\n",
    "- **Flesch-Kincaid**: Reading grade level (target ‚â§ 6)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.6: DEFINE EVALUATION METRICS\n",
      "======================================================================\n",
      "\n",
      "üì¶ Loading evaluation metrics...\n",
      "   ‚úì ROUGE metric loaded\n",
      "   ‚úì BERTScore metric loaded\n",
      "   ‚úì SARI metric loaded\n",
      "\n",
      "‚úÖ compute_metrics() function defined\n",
      "\n",
      "üìä Metric Targets:\n",
      "   ROUGE-L: Higher is better\n",
      "   SARI: ‚â•40 (good simplification)\n",
      "   BERTScore-F1: Higher is better\n",
      "   FK-Grade: ‚â§6 (6th grade reading level)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.6 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.6: DEFINE EVALUATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.6: DEFINE EVALUATION METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load Evaluation Metrics\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print loading status\n",
    "print(f\"\\nüì¶ Loading evaluation metrics...\")\n",
    "\n",
    "# Load ROUGE metric from HuggingFace evaluate library\n",
    "# ROUGE-L measures longest common subsequence between prediction and reference\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "print(f\"   ‚úì ROUGE metric loaded\")\n",
    "\n",
    "# Load BERTScore metric from HuggingFace evaluate library\n",
    "# BERTScore measures semantic similarity using contextual embeddings\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "print(f\"   ‚úì BERTScore metric loaded\")\n",
    "\n",
    "# Load SARI metric from HuggingFace evaluate library\n",
    "# SARI (System output Against References and against the Input)\n",
    "# Specifically designed for text simplification evaluation\n",
    "sari_metric = evaluate.load(\"sari\")\n",
    "print(f\"   ‚úì SARI metric loaded\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Evaluation Function\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def compute_metrics(\n",
    "    predictions: List[str],\n",
    "    references: List[str],\n",
    "    sources: List[str],\n",
    "    compute_bertscore: bool = True\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute all evaluation metrics for simplification quality.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of model-generated simplified texts\n",
    "        references: List of ground truth simplified texts (from Claude)\n",
    "        sources: List of original complex medical texts\n",
    "        compute_bertscore: Whether to compute BERTScore (slower, GPU-intensive)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all metric scores and statistics\n",
    "    \"\"\"\n",
    "    # Initialize empty metrics dictionary\n",
    "    metrics = {}\n",
    "    \n",
    "    # Filter out samples with empty predictions (model failures)\n",
    "    # Get indices of valid (non-empty) predictions\n",
    "    valid_indices = [i for i, p in enumerate(predictions) if p.strip()]\n",
    "    # Extract valid predictions using filtered indices\n",
    "    valid_predictions = [predictions[i] for i in valid_indices]\n",
    "    # Extract corresponding references\n",
    "    valid_references = [references[i] for i in valid_indices]\n",
    "    # Extract corresponding source texts\n",
    "    valid_sources = [sources[i] for i in valid_indices]\n",
    "    \n",
    "    # Handle edge case where all predictions are empty\n",
    "    if len(valid_predictions) == 0:\n",
    "        # Return default/penalty values for all metrics\n",
    "        return {\n",
    "            \"ROUGE-L\": 0.0,  # Zero overlap\n",
    "            \"SARI\": 0.0,  # Zero simplification quality\n",
    "            \"BERTScore-F1\": 0.0,  # Zero semantic similarity\n",
    "            \"FK-Grade-Mean\": 15.0,  # Penalty grade level (very high)\n",
    "            \"FK-Grade-Std\": 0.0,  # No variation\n",
    "            \"valid_samples\": 0,  # No valid samples\n",
    "            \"total_samples\": len(predictions),  # Track total attempted\n",
    "        }\n",
    "    \n",
    "    # Compute ROUGE-L score (longest common subsequence)\n",
    "    rouge_results = rouge_metric.compute(\n",
    "        predictions=valid_predictions,  # Model outputs\n",
    "        references=valid_references,  # Ground truth\n",
    "        use_stemmer=True  # Use Porter stemmer for better matching\n",
    "    )\n",
    "    # Extract ROUGE-L F1 score and convert to float\n",
    "    metrics[\"ROUGE-L\"] = float(rouge_results[\"rougeL\"])\n",
    "    \n",
    "    # Compute SARI score (simplification-specific metric)\n",
    "    # SARI requires sources to compute add/keep/delete operations\n",
    "    sari_results = sari_metric.compute(\n",
    "        sources=valid_sources,  # Original complex texts\n",
    "        predictions=valid_predictions,  # Model outputs\n",
    "        references=[[ref] for ref in valid_references]  # Wrap each ref in list (SARI format)\n",
    "    )\n",
    "    # Extract SARI score and convert to float\n",
    "    metrics[\"SARI\"] = float(sari_results[\"sari\"])\n",
    "    \n",
    "    # Compute BERTScore (optional, computationally expensive)\n",
    "    if compute_bertscore:\n",
    "        # Compute BERTScore using DeBERTa model for semantic similarity\n",
    "        bertscore_results = bertscore_metric.compute(\n",
    "            predictions=valid_predictions,  # Model outputs\n",
    "            references=valid_references,  # Ground truth\n",
    "            lang=\"en\",  # English language\n",
    "            model_type=\"microsoft/deberta-xlarge-mnli\"  # High-quality model\n",
    "        )\n",
    "        # Calculate mean F1 score across all samples\n",
    "        metrics[\"BERTScore-F1\"] = float(np.mean(bertscore_results[\"f1\"]))\n",
    "    else:\n",
    "        # Skip BERTScore computation (for speed)\n",
    "        metrics[\"BERTScore-F1\"] = None\n",
    "    \n",
    "    # Compute Flesch-Kincaid Grade Level for each prediction\n",
    "    fk_grades = []  # List to store individual FK grades\n",
    "    for pred in valid_predictions:\n",
    "        # Check if prediction has content\n",
    "        if pred.strip():\n",
    "            # Compute FK grade level using textstat library\n",
    "            fk = textstat.flesch_kincaid_grade(pred)\n",
    "            fk_grades.append(fk)\n",
    "        else:\n",
    "            # Assign penalty grade for empty predictions\n",
    "            fk_grades.append(15.0)\n",
    "    \n",
    "    # Calculate mean FK grade across all predictions\n",
    "    metrics[\"FK-Grade-Mean\"] = float(np.mean(fk_grades))\n",
    "    # Calculate standard deviation of FK grades\n",
    "    metrics[\"FK-Grade-Std\"] = float(np.std(fk_grades))\n",
    "    # Store count of valid samples\n",
    "    metrics[\"valid_samples\"] = len(valid_predictions)\n",
    "    # Store total sample count\n",
    "    metrics[\"total_samples\"] = len(predictions)\n",
    "    \n",
    "    # Return complete metrics dictionary\n",
    "    return metrics\n",
    "\n",
    "# Print confirmation of function definition\n",
    "print(f\"\\n‚úÖ compute_metrics() function defined\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Metric Targets (from Master Plan)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print metric targets for reference\n",
    "print(f\"\\nüìä Metric Targets:\")\n",
    "\n",
    "# Define target values/directions for each metric (from Master Plan)\n",
    "METRIC_TARGETS = {\n",
    "    \"ROUGE-L\": \"Higher is better\",  # Maximize overlap with reference\n",
    "    \"SARI\": \"‚â•40 (good simplification)\",  # Target threshold for quality\n",
    "    \"BERTScore-F1\": \"Higher is better\",  # Maximize semantic similarity\n",
    "    \"FK-Grade\": \"‚â§6 (6th grade reading level)\",  # Target accessibility level\n",
    "}\n",
    "\n",
    "# Print each metric and its target\n",
    "for metric, target in METRIC_TARGETS.items():\n",
    "    print(f\"   {metric}: {target}\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.6 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.7: Define Zero-Shot Inference Function\n",
    "\n",
    "Define the function for generating predictions using model-specific formats.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.7: DEFINE ZERO-SHOT INFERENCE FUNCTION\n",
      "======================================================================\n",
      "\n",
      "‚úÖ load_model_for_inference() defined\n",
      "‚úÖ generate_predictions() defined (with intermediate checkpointing)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.7 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.7: DEFINE ZERO-SHOT INFERENCE FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.7: DEFINE ZERO-SHOT INFERENCE FUNCTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def load_model_for_inference(\n",
    "    model_name: str,\n",
    "    device_map: str = \"auto\"\n",
    ") -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "    \"\"\"\n",
    "    Load a model and its tokenizer for inference.\n",
    "    \n",
    "    Downloads the model if not cached, then loads it in BF16 precision\n",
    "    for efficient GPU inference.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Key from STUDENT_MODELS dictionary\n",
    "        device_map: Device placement strategy ('auto' distributes across GPUs)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (model, tokenizer) ready for inference\n",
    "    \"\"\"\n",
    "    # Get model configuration from STUDENT_MODELS dictionary\n",
    "    config = STUDENT_MODELS[model_name]\n",
    "    # Extract HuggingFace model path\n",
    "    model_path = config[\"path\"]\n",
    "    \n",
    "    # Print loading status\n",
    "    print(f\"\\nüì• Loading {model_name}...\")\n",
    "    print(f\"   Path: {model_path}\")\n",
    "    print(f\"   Format: {config['prompt_format']}\")\n",
    "    \n",
    "    # Pre-download model files if not already cached\n",
    "    print(f\"   Ensuring model is downloaded...\")\n",
    "    snapshot_download(\n",
    "        repo_id=model_path,  # HuggingFace repository ID\n",
    "        token=os.environ.get(\"HF_TOKEN\"),  # Authentication token if needed\n",
    "        ignore_patterns=[\"*.msgpack\", \"*.h5\"]  # Skip unnecessary file formats\n",
    "    )\n",
    "    \n",
    "    # Load tokenizer from downloaded/cached files\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_path,  # Model path\n",
    "        trust_remote_code=True,  # Allow custom tokenizer code\n",
    "        padding_side=\"right\",  # Pad on right side for causal LM\n",
    "        local_files_only=True  # Use cached files only (already downloaded)\n",
    "    )\n",
    "    \n",
    "    # Set pad token if not defined (common for Llama-based models)\n",
    "    if tokenizer.pad_token is None:\n",
    "        # Use EOS token as padding token\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # Load model in BF16 precision for efficient inference\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,  # Model path\n",
    "        torch_dtype=torch.bfloat16,  # Use BF16 for memory efficiency\n",
    "        device_map=device_map,  # Auto-distribute across available GPUs\n",
    "        trust_remote_code=True,  # Allow custom model code\n",
    "        local_files_only=True  # Use cached files only\n",
    "    )\n",
    "    \n",
    "    # Set model to evaluation mode (disables dropout, etc.)\n",
    "    model.eval()\n",
    "    # Print success message\n",
    "    print(f\"   ‚úì Model loaded successfully\")\n",
    "    # Print current GPU memory usage\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # Return model and tokenizer tuple\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_predictions(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    test_samples: List[Dict],\n",
    "    prompt_format: str,\n",
    "    max_new_tokens: int = 512,\n",
    "    batch_size: int = 1,\n",
    "    checkpoint_path: Optional[Path] = None,\n",
    "    save_every: int = 100\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate predictions for test samples with intermediate checkpointing.\n",
    "    \n",
    "    Processes samples sequentially (batch_size=1) to avoid OOM issues.\n",
    "    Uses greedy decoding (do_sample=False) for reproducibility.\n",
    "    Saves checkpoints every `save_every` samples to enable recovery.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded model for generation\n",
    "        tokenizer: Corresponding tokenizer\n",
    "        test_samples: List of dicts with 'complex_text' and 'reference'\n",
    "        prompt_format: Either 'chatml' or 'mistral'\n",
    "        max_new_tokens: Maximum tokens to generate\n",
    "        batch_size: Batch size (currently only 1 supported)\n",
    "        checkpoint_path: Path to save/load intermediate checkpoints (None to disable)\n",
    "        save_every: Save checkpoint every N samples (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts with predictions added to each sample\n",
    "    \"\"\"\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    # Track starting index (0 if fresh start, or resume point)\n",
    "    start_idx = 0\n",
    "    \n",
    "    # Check if checkpoint exists and load it for resumption\n",
    "    if checkpoint_path is not None and checkpoint_path.exists():\n",
    "        # Load existing checkpoint\n",
    "        with open(checkpoint_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "        # Restore previous results\n",
    "        results = checkpoint_data.get(\"predictions\", [])\n",
    "        # Set start index to continue from where we left off\n",
    "        start_idx = len(results)\n",
    "        # Print resumption status\n",
    "        print(f\"   ‚ö° Resuming from checkpoint: {start_idx}/{len(test_samples)} samples completed\")\n",
    "    \n",
    "    # Check if already fully completed\n",
    "    if start_idx >= len(test_samples):\n",
    "        # All samples already processed\n",
    "        print(f\"   ‚úì All {len(test_samples)} samples already completed\")\n",
    "        return results\n",
    "    \n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for inference (saves memory)\n",
    "    with torch.no_grad():\n",
    "        # Iterate through remaining test samples with progress bar\n",
    "        for i, sample in enumerate(tqdm(test_samples[start_idx:], \n",
    "                                         desc=\"Generating predictions\",\n",
    "                                         initial=start_idx,\n",
    "                                         total=len(test_samples))):\n",
    "            # Calculate actual index in full dataset\n",
    "            actual_idx = start_idx + i\n",
    "            \n",
    "            # Format prompt using model-specific inference template\n",
    "            prompt = format_inference_prompt(\n",
    "                instruction=TASK_INSTRUCTION,  # Task instruction\n",
    "                input_text=sample[\"complex_text\"],  # Complex text to simplify\n",
    "                prompt_format=prompt_format  # Model-specific format\n",
    "            )\n",
    "            \n",
    "            # Tokenize the prompt\n",
    "            inputs = tokenizer(\n",
    "                prompt,  # Formatted prompt string\n",
    "                return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "                truncation=True,  # Truncate if too long\n",
    "                max_length=2048  # Maximum input length\n",
    "            ).to(model.device)  # Move to same device as model\n",
    "            \n",
    "            # Generate output tokens\n",
    "            outputs = model.generate(\n",
    "                **inputs,  # Unpack input tensors\n",
    "                max_new_tokens=max_new_tokens,  # Limit output length\n",
    "                do_sample=False,  # Greedy decoding for reproducibility\n",
    "                pad_token_id=tokenizer.pad_token_id,  # Pad token for batching\n",
    "                eos_token_id=tokenizer.eos_token_id,  # Stop token\n",
    "            )\n",
    "            \n",
    "            # Extract only the newly generated tokens (exclude input)\n",
    "            generated_ids = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "            # Decode tokens to text, removing special tokens\n",
    "            generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            # Clean up the output text\n",
    "            generated_text = generated_text.strip()\n",
    "            \n",
    "            # Remove any remaining format artifacts (template tags)\n",
    "            for artifact in [\"<|im_end|>\", \"</s>\", \"[/INST]\"]:\n",
    "                generated_text = generated_text.replace(artifact, \"\").strip()\n",
    "            \n",
    "            # Append result with all relevant information\n",
    "            results.append({\n",
    "                \"idx\": sample[\"idx\"],  # Sample index\n",
    "                \"complex_text\": sample[\"complex_text\"],  # Original input\n",
    "                \"reference\": sample[\"reference\"],  # Ground truth\n",
    "                \"prediction\": generated_text,  # Model output\n",
    "            })\n",
    "            \n",
    "            # Save intermediate checkpoint every `save_every` samples\n",
    "            # Also save on the last sample\n",
    "            current_count = actual_idx + 1  # 1-indexed count of completed samples\n",
    "            is_checkpoint_interval = (current_count % save_every == 0)  # Check if at interval\n",
    "            is_last_sample = (current_count == len(test_samples))  # Check if last sample\n",
    "            \n",
    "            if checkpoint_path is not None and (is_checkpoint_interval or is_last_sample):\n",
    "                # Create checkpoint data dictionary\n",
    "                checkpoint_data = {\n",
    "                    \"predictions\": results,  # All predictions so far\n",
    "                    \"completed\": current_count,  # Number of completed samples\n",
    "                    \"total\": len(test_samples),  # Total samples\n",
    "                    \"timestamp\": datetime.now().isoformat(),  # Checkpoint time\n",
    "                    \"is_complete\": is_last_sample,  # Mark if fully complete\n",
    "                }\n",
    "                # Save checkpoint to file\n",
    "                with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n",
    "                # Print checkpoint status (only at intervals, not last)\n",
    "                if is_checkpoint_interval and not is_last_sample:\n",
    "                    print(f\"\\n   üíæ Checkpoint saved: {current_count}/{len(test_samples)} samples\")\n",
    "    \n",
    "    # Return list of all results\n",
    "    return results\n",
    "\n",
    "# Print confirmation of function definitions\n",
    "print(f\"\\n‚úÖ load_model_for_inference() defined\")\n",
    "print(f\"‚úÖ generate_predictions() defined (with intermediate checkpointing)\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.7 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.8: Baseline Evaluation Preparation\n",
    "\n",
    "Prepare for baseline evaluation of all three models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.8: BASELINE EVALUATION PREPARATION\n",
      "======================================================================\n",
      "\n",
      "üìã Baseline Evaluation Order:\n",
      "   1. OpenBioLLM-8B (chatml format) - Medical\n",
      "   2. BioMistral-7B-DARE (mistral format) - Medical\n",
      "   3. Mistral-7B (mistral format) - General\n",
      "\n",
      "üìä Test Set Statistics:\n",
      "   ‚úì Total samples: 1,001\n",
      "   ‚úì Reference FK Mean: 7.23\n",
      "\n",
      "‚úÖ Checkpoint functions defined:\n",
      "   ‚úì save_baseline_checkpoint(model_name, predictions, metrics)\n",
      "   ‚úì load_baseline_checkpoint(model_name)\n",
      "   ‚úì load_all_baseline_checkpoints()\n",
      "\n",
      "üìã Checkpoint Status:\n",
      "   ‚óã OpenBioLLM-8B: pending\n",
      "   ‚óã BioMistral-7B-DARE: pending\n",
      "   ‚óã Mistral-7B: pending\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.8 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.8: BASELINE EVALUATION PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.8: BASELINE EVALUATION PREPARATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define the order of models to evaluate (matches Master Plan)\n",
    "# Order: OpenBioLLM (ChatML), BioMistral (Mistral), Mistral-7B (Mistral)\n",
    "BASELINE_EVAL_ORDER = [\n",
    "    \"OpenBioLLM-8B\",       # Section 5.9.1 - ChatML format, Medical model\n",
    "    \"BioMistral-7B-DARE\",  # Section 5.9.2 - Mistral format, Medical model\n",
    "    \"Mistral-7B\",          # Section 5.9.3 - Mistral format, General model\n",
    "]\n",
    "\n",
    "# Print evaluation order with configuration details\n",
    "print(f\"\\nüìã Baseline Evaluation Order:\")\n",
    "for i, model_name in enumerate(BASELINE_EVAL_ORDER, 1):\n",
    "    # Get configuration for current model\n",
    "    config = STUDENT_MODELS[model_name]\n",
    "    # Print model details\n",
    "    print(f\"   {i}. {model_name} ({config['prompt_format']} format) - {config['type']}\")\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "# Will be populated during sections 5.9.1-5.9.3\n",
    "baseline_results = {}  # Stores computed metrics for each model\n",
    "baseline_predictions = {}  # Stores raw predictions for each model\n",
    "\n",
    "# Print test set statistics for reference\n",
    "print(f\"\\nüìä Test Set Statistics:\")\n",
    "print(f\"   ‚úì Total samples: {len(test_samples):,}\")\n",
    "print(f\"   ‚úì Reference FK Mean: {REFERENCE_STATS['fk_mean']:.2f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Checkpoint Functions (Per-Model to Avoid Race Conditions)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def save_baseline_checkpoint(model_name: str, predictions: List[Dict], metrics: Dict):\n",
    "    \"\"\"\n",
    "    Save baseline checkpoint for a specific model.\n",
    "    Uses per-model checkpoint files to avoid race conditions in parallel execution.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model being checkpointed\n",
    "        predictions: List of prediction dictionaries\n",
    "        metrics: Dictionary of computed metrics\n",
    "    \"\"\"\n",
    "    # Create per-model checkpoint data (not shared file)\n",
    "    model_checkpoint = {\n",
    "        \"model_name\": model_name,  # Store model name for verification\n",
    "        \"metrics\": metrics,  # Computed metric values\n",
    "        \"n_predictions\": len(predictions),  # Number of predictions\n",
    "        \"timestamp\": datetime.now().isoformat(),  # Completion time\n",
    "        \"is_complete\": True,  # Mark as complete\n",
    "    }\n",
    "    \n",
    "    # Build path to model-specific checkpoint file\n",
    "    checkpoint_path = BASELINE_DIR / f\"baseline_checkpoint_{model_name.lower().replace('-', '_')}.json\"\n",
    "    # Save checkpoint to JSON file\n",
    "    with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(model_checkpoint, f, indent=2)\n",
    "    \n",
    "    # Also save full predictions to separate file\n",
    "    pred_path = BASELINE_DIR / f\"baseline_{model_name.lower().replace('-', '_')}.json\"\n",
    "    # Save predictions to JSON file with unicode support\n",
    "    with open(pred_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Print confirmation\n",
    "    print(f\"   ‚úì Checkpoint saved for {model_name}\")\n",
    "\n",
    "def load_baseline_checkpoint(model_name: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Load baseline checkpoint for a specific model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model to load checkpoint for\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with checkpoint data, or None if no checkpoint exists\n",
    "    \"\"\"\n",
    "    # Build path to model-specific checkpoint file\n",
    "    checkpoint_path = BASELINE_DIR / f\"baseline_checkpoint_{model_name.lower().replace('-', '_')}.json\"\n",
    "    \n",
    "    # Check if checkpoint file exists\n",
    "    if checkpoint_path.exists():\n",
    "        # Load and return checkpoint data\n",
    "        with open(checkpoint_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Return None if no checkpoint found\n",
    "    return None\n",
    "\n",
    "def load_all_baseline_checkpoints() -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load all existing baseline checkpoints.\n",
    "    Used by Section 5.10 to aggregate results from parallel runs.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping model names to their checkpoint data\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary\n",
    "    all_checkpoints = {}\n",
    "    \n",
    "    # Iterate through each model in evaluation order\n",
    "    for model_name in BASELINE_EVAL_ORDER:\n",
    "        # Attempt to load checkpoint for this model\n",
    "        checkpoint = load_baseline_checkpoint(model_name)\n",
    "        # If checkpoint exists, add to results\n",
    "        if checkpoint is not None:\n",
    "            all_checkpoints[model_name] = checkpoint\n",
    "    \n",
    "    # Return all loaded checkpoints\n",
    "    return all_checkpoints\n",
    "\n",
    "# Print confirmation of function definitions\n",
    "print(f\"\\n‚úÖ Checkpoint functions defined:\")\n",
    "print(f\"   ‚úì save_baseline_checkpoint(model_name, predictions, metrics)\")\n",
    "print(f\"   ‚úì load_baseline_checkpoint(model_name)\")\n",
    "print(f\"   ‚úì load_all_baseline_checkpoints()\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Check Existing Checkpoint Status\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print checkpoint status header\n",
    "print(f\"\\nüìã Checkpoint Status:\")\n",
    "# Check status for each model\n",
    "for model_name in BASELINE_EVAL_ORDER:\n",
    "    # Attempt to load checkpoint for this model\n",
    "    checkpoint = load_baseline_checkpoint(model_name)\n",
    "    # Print status based on checkpoint existence\n",
    "    if checkpoint is not None:\n",
    "        print(f\"   ‚úì {model_name}: completed\")\n",
    "    else:\n",
    "        print(f\"   ‚óã {model_name}: pending\")\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.8 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.9.1: OpenBioLLM-8B Baseline (ChatML)\n",
    "\n",
    "Evaluate OpenBioLLM-8B zero-shot performance using **ChatML format**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.9.1: OpenBioLLM-8B BASELINE (ChatML)\n",
      "======================================================================\n",
      "\n",
      "üöÄ Running OpenBioLLM-8B baseline evaluation...\n",
      "   Format: chatml\n",
      "   Samples: 1001\n",
      "   Checkpoint: /workspace/medisimplifier/results/baseline/generation_checkpoint_openbiollm_8b.json\n",
      "\n",
      "üì• Loading OpenBioLLM-8B...\n",
      "   Path: aaditya/Llama3-OpenBioLLM-8B\n",
      "   Format: chatml\n",
      "   Ensuring model is downloaded...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1505d79c98b46b5a9c8d2c37b731337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5965087dbe5242c6b80b5a6d5248e8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Model loaded successfully\n",
      "   GPU Memory: 32.2GB allocated, 32.2GB reserved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f14c0c0888491c8ad9416979399e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üíæ Checkpoint saved: 100/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 200/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 300/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 400/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 500/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 600/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 700/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 800/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 900/1001 samples\n",
      "\n",
      "   üíæ Checkpoint saved: 1000/1001 samples\n",
      "\n",
      "üìä Computing metrics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e278d67fe9247149b470d334b6ba4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a08016509fb48a3a3c0283d12da9c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2383ef962a4767b4794ecfb887e770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b47826810d649d08591d8adb33f1d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dce07796204640ae52fb9946e96725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfb8da72e084863a1c32c8945a8d08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Checkpoint saved for OpenBioLLM-8B\n",
      "   ‚úì Removed intermediate checkpoint\n",
      "\n",
      "üìä OpenBioLLM-8B Baseline Results:\n",
      "   ROUGE-L: 0.2623\n",
      "   SARI: 36.98\n",
      "   BERTScore-F1: 0.6371\n",
      "   FK-Grade: 12.53 (¬±3.70)\n",
      "   Valid samples: 1001/1001\n",
      "   Time: 59.9 minutes\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.9.1 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.9.1: OpenBioLLM-8B BASELINE (ChatML)\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.9.1: OpenBioLLM-8B BASELINE (ChatML)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set current model name for this evaluation\n",
    "MODEL_NAME = \"OpenBioLLM-8B\"\n",
    "# Get prompt format from model configuration (should be 'chatml')\n",
    "PROMPT_FORMAT = STUDENT_MODELS[MODEL_NAME][\"prompt_format\"]\n",
    "\n",
    "# Define checkpoint path for intermediate saves during generation\n",
    "# This allows resuming if the process is interrupted mid-evaluation\n",
    "GENERATION_CHECKPOINT_PATH = BASELINE_DIR / f\"generation_checkpoint_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "\n",
    "# Check if this model was already fully evaluated (per-model checkpoint)\n",
    "existing_checkpoint = load_baseline_checkpoint(MODEL_NAME)\n",
    "# If model already completed, load results from checkpoint\n",
    "if existing_checkpoint is not None:\n",
    "    # Print notice about loading from checkpoint\n",
    "    print(f\"\\n‚ö†Ô∏è {MODEL_NAME} baseline already completed. Loading from checkpoint...\")\n",
    "    # Load metrics from checkpoint\n",
    "    baseline_results[MODEL_NAME] = existing_checkpoint[\"metrics\"]\n",
    "    \n",
    "    # Load full predictions from saved file\n",
    "    pred_path = BASELINE_DIR / f\"baseline_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "    with open(pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        baseline_predictions[MODEL_NAME] = json.load(f)\n",
    "    \n",
    "    # Print loaded results summary\n",
    "    print(f\"   ‚úì Loaded {len(baseline_predictions[MODEL_NAME])} predictions\")\n",
    "    print(f\"   ‚úì ROUGE-L: {baseline_results[MODEL_NAME]['ROUGE-L']:.4f}\")\n",
    "    print(f\"   ‚úì SARI: {baseline_results[MODEL_NAME]['SARI']:.2f}\")\n",
    "    print(f\"   ‚úì FK-Grade: {baseline_results[MODEL_NAME]['FK-Grade-Mean']:.2f}\")\n",
    "else:\n",
    "    # Run baseline evaluation (fresh or resumed)\n",
    "    print(f\"\\nüöÄ Running {MODEL_NAME} baseline evaluation...\")\n",
    "    print(f\"   Format: {PROMPT_FORMAT}\")\n",
    "    print(f\"   Samples: {len(test_samples)}\")\n",
    "    print(f\"   Checkpoint: {GENERATION_CHECKPOINT_PATH}\")\n",
    "    \n",
    "    # Record start time for duration tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Clear GPU memory before loading model\n",
    "    clear_memory()\n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = load_model_for_inference(MODEL_NAME)\n",
    "    \n",
    "    # Generate predictions for all test samples (with checkpointing)\n",
    "    predictions = generate_predictions(\n",
    "        model=model,  # Loaded model\n",
    "        tokenizer=tokenizer,  # Loaded tokenizer\n",
    "        test_samples=test_samples,  # Test data\n",
    "        prompt_format=PROMPT_FORMAT,  # ChatML format\n",
    "        max_new_tokens=MAX_NEW_TOKENS,  # Generation limit\n",
    "        checkpoint_path=GENERATION_CHECKPOINT_PATH,  # Intermediate checkpoint path\n",
    "        save_every=100  # Save every 100 samples\n",
    "    )\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    print(f\"\\nüìä Computing metrics...\")\n",
    "    metrics = compute_metrics(\n",
    "        predictions=[p[\"prediction\"] for p in predictions],  # Extract predictions\n",
    "        references=[p[\"reference\"] for p in predictions],  # Extract references\n",
    "        sources=[p[\"complex_text\"] for p in predictions],  # Extract sources\n",
    "        compute_bertscore=True  # Include BERTScore\n",
    "    )\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed = time.time() - start_time\n",
    "    # Add timing to metrics\n",
    "    metrics[\"elapsed_time\"] = elapsed\n",
    "    \n",
    "    # Store results in global dictionaries\n",
    "    baseline_results[MODEL_NAME] = metrics\n",
    "    baseline_predictions[MODEL_NAME] = predictions\n",
    "    \n",
    "    # Save final checkpoint for recovery (per-model file)\n",
    "    save_baseline_checkpoint(MODEL_NAME, predictions, metrics)\n",
    "    \n",
    "    # Remove intermediate generation checkpoint (no longer needed)\n",
    "    if GENERATION_CHECKPOINT_PATH.exists():\n",
    "        GENERATION_CHECKPOINT_PATH.unlink()  # Delete the file\n",
    "        print(f\"   ‚úì Removed intermediate checkpoint\")\n",
    "    \n",
    "    # Print results summary\n",
    "    print(f\"\\nüìä {MODEL_NAME} Baseline Results:\")\n",
    "    print(f\"   ROUGE-L: {metrics['ROUGE-L']:.4f}\")\n",
    "    print(f\"   SARI: {metrics['SARI']:.2f}\")\n",
    "    print(f\"   BERTScore-F1: {metrics['BERTScore-F1']:.4f}\")\n",
    "    print(f\"   FK-Grade: {metrics['FK-Grade-Mean']:.2f} (¬±{metrics['FK-Grade-Std']:.2f})\")\n",
    "    print(f\"   Valid samples: {metrics['valid_samples']}/{metrics['total_samples']}\")\n",
    "    print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Clean up: delete model and tokenizer to free memory\n",
    "    del model, tokenizer\n",
    "    # Clear GPU memory\n",
    "    clear_memory()\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.9.1 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.9.2: BioMistral-7B-DARE Baseline (Mistral)\n",
    "\n",
    "Evaluate BioMistral-7B-DARE zero-shot performance using **Mistral format**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.9.2: BioMistral-7B-DARE BASELINE (Mistral)\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è BioMistral-7B-DARE baseline already completed. Loading from checkpoint...\n",
      "   ‚úì Loaded 1001 predictions\n",
      "   ‚úì ROUGE-L: 0.4120\n",
      "   ‚úì SARI: 51.91\n",
      "   ‚úì FK-Grade: 9.52\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.9.2 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.9.2: BioMistral-7B-DARE BASELINE (Mistral)\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.9.2: BioMistral-7B-DARE BASELINE (Mistral)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set current model name for this evaluation\n",
    "MODEL_NAME = \"BioMistral-7B-DARE\"\n",
    "# Get prompt format from model configuration (should be 'mistral')\n",
    "PROMPT_FORMAT = STUDENT_MODELS[MODEL_NAME][\"prompt_format\"]\n",
    "\n",
    "# Define checkpoint path for intermediate saves during generation\n",
    "# This allows resuming if the process is interrupted mid-evaluation\n",
    "GENERATION_CHECKPOINT_PATH = BASELINE_DIR / f\"generation_checkpoint_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "\n",
    "# Check if this model was already fully evaluated (per-model checkpoint)\n",
    "existing_checkpoint = load_baseline_checkpoint(MODEL_NAME)\n",
    "# If model already completed, load results from checkpoint\n",
    "if existing_checkpoint is not None:\n",
    "    # Print notice about loading from checkpoint\n",
    "    print(f\"\\n‚ö†Ô∏è {MODEL_NAME} baseline already completed. Loading from checkpoint...\")\n",
    "    # Load metrics from checkpoint\n",
    "    baseline_results[MODEL_NAME] = existing_checkpoint[\"metrics\"]\n",
    "    \n",
    "    # Load full predictions from saved file\n",
    "    pred_path = BASELINE_DIR / f\"baseline_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "    with open(pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        baseline_predictions[MODEL_NAME] = json.load(f)\n",
    "    \n",
    "    # Print loaded results summary\n",
    "    print(f\"   ‚úì Loaded {len(baseline_predictions[MODEL_NAME])} predictions\")\n",
    "    print(f\"   ‚úì ROUGE-L: {baseline_results[MODEL_NAME]['ROUGE-L']:.4f}\")\n",
    "    print(f\"   ‚úì SARI: {baseline_results[MODEL_NAME]['SARI']:.2f}\")\n",
    "    print(f\"   ‚úì FK-Grade: {baseline_results[MODEL_NAME]['FK-Grade-Mean']:.2f}\")\n",
    "else:\n",
    "    # Run baseline evaluation (fresh or resumed)\n",
    "    print(f\"\\nüöÄ Running {MODEL_NAME} baseline evaluation...\")\n",
    "    print(f\"   Format: {PROMPT_FORMAT}\")\n",
    "    print(f\"   Samples: {len(test_samples)}\")\n",
    "    print(f\"   Checkpoint: {GENERATION_CHECKPOINT_PATH}\")\n",
    "    \n",
    "    # Record start time for duration tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Clear GPU memory before loading model\n",
    "    clear_memory()\n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = load_model_for_inference(MODEL_NAME)\n",
    "    \n",
    "    # Generate predictions for all test samples (with checkpointing)\n",
    "    predictions = generate_predictions(\n",
    "        model=model,  # Loaded model\n",
    "        tokenizer=tokenizer,  # Loaded tokenizer\n",
    "        test_samples=test_samples,  # Test data\n",
    "        prompt_format=PROMPT_FORMAT,  # Mistral format\n",
    "        max_new_tokens=MAX_NEW_TOKENS,  # Generation limit\n",
    "        checkpoint_path=GENERATION_CHECKPOINT_PATH,  # Intermediate checkpoint path\n",
    "        save_every=100  # Save every 100 samples\n",
    "    )\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    print(f\"\\nüìä Computing metrics...\")\n",
    "    metrics = compute_metrics(\n",
    "        predictions=[p[\"prediction\"] for p in predictions],  # Extract predictions\n",
    "        references=[p[\"reference\"] for p in predictions],  # Extract references\n",
    "        sources=[p[\"complex_text\"] for p in predictions],  # Extract sources\n",
    "        compute_bertscore=True  # Include BERTScore\n",
    "    )\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed = time.time() - start_time\n",
    "    # Add timing to metrics\n",
    "    metrics[\"elapsed_time\"] = elapsed\n",
    "    \n",
    "    # Store results in global dictionaries\n",
    "    baseline_results[MODEL_NAME] = metrics\n",
    "    baseline_predictions[MODEL_NAME] = predictions\n",
    "    \n",
    "    # Save final checkpoint for recovery (per-model file)\n",
    "    save_baseline_checkpoint(MODEL_NAME, predictions, metrics)\n",
    "    \n",
    "    # Remove intermediate generation checkpoint (no longer needed)\n",
    "    if GENERATION_CHECKPOINT_PATH.exists():\n",
    "        GENERATION_CHECKPOINT_PATH.unlink()  # Delete the file\n",
    "        print(f\"   ‚úì Removed intermediate checkpoint\")\n",
    "    \n",
    "    # Print results summary\n",
    "    print(f\"\\nüìä {MODEL_NAME} Baseline Results:\")\n",
    "    print(f\"   ROUGE-L: {metrics['ROUGE-L']:.4f}\")\n",
    "    print(f\"   SARI: {metrics['SARI']:.2f}\")\n",
    "    print(f\"   BERTScore-F1: {metrics['BERTScore-F1']:.4f}\")\n",
    "    print(f\"   FK-Grade: {metrics['FK-Grade-Mean']:.2f} (¬±{metrics['FK-Grade-Std']:.2f})\")\n",
    "    print(f\"   Valid samples: {metrics['valid_samples']}/{metrics['total_samples']}\")\n",
    "    print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Clean up: delete model and tokenizer to free memory\n",
    "    del model, tokenizer\n",
    "    # Clear GPU memory\n",
    "    clear_memory()\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.9.2 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.9.3: Mistral-7B Baseline (Mistral)\n",
    "\n",
    "Evaluate Mistral-7B-Instruct-v0.2 zero-shot performance using **Mistral format**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.9.3: Mistral-7B BASELINE (Mistral)\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è Mistral-7B baseline already completed. Loading from checkpoint...\n",
      "   ‚úì Loaded 1001 predictions\n",
      "   ‚úì ROUGE-L: 0.3912\n",
      "   ‚úì SARI: 46.38\n",
      "   ‚úì FK-Grade: 10.60\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SECTION 5.9.3 COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.9.3: Mistral-7B BASELINE (Mistral)\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.9.3: Mistral-7B BASELINE (Mistral)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set current model name for this evaluation\n",
    "MODEL_NAME = \"Mistral-7B\"\n",
    "# Get prompt format from model configuration (should be 'mistral')\n",
    "PROMPT_FORMAT = STUDENT_MODELS[MODEL_NAME][\"prompt_format\"]\n",
    "\n",
    "# Define checkpoint path for intermediate saves during generation\n",
    "# This allows resuming if the process is interrupted mid-evaluation\n",
    "GENERATION_CHECKPOINT_PATH = BASELINE_DIR / f\"generation_checkpoint_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "\n",
    "# Check if this model was already fully evaluated (per-model checkpoint)\n",
    "existing_checkpoint = load_baseline_checkpoint(MODEL_NAME)\n",
    "# If model already completed, load results from checkpoint\n",
    "if existing_checkpoint is not None:\n",
    "    # Print notice about loading from checkpoint\n",
    "    print(f\"\\n‚ö†Ô∏è {MODEL_NAME} baseline already completed. Loading from checkpoint...\")\n",
    "    # Load metrics from checkpoint\n",
    "    baseline_results[MODEL_NAME] = existing_checkpoint[\"metrics\"]\n",
    "    \n",
    "    # Load full predictions from saved file\n",
    "    pred_path = BASELINE_DIR / f\"baseline_{MODEL_NAME.lower().replace('-', '_')}.json\"\n",
    "    with open(pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        baseline_predictions[MODEL_NAME] = json.load(f)\n",
    "    \n",
    "    # Print loaded results summary\n",
    "    print(f\"   ‚úì Loaded {len(baseline_predictions[MODEL_NAME])} predictions\")\n",
    "    print(f\"   ‚úì ROUGE-L: {baseline_results[MODEL_NAME]['ROUGE-L']:.4f}\")\n",
    "    print(f\"   ‚úì SARI: {baseline_results[MODEL_NAME]['SARI']:.2f}\")\n",
    "    print(f\"   ‚úì FK-Grade: {baseline_results[MODEL_NAME]['FK-Grade-Mean']:.2f}\")\n",
    "else:\n",
    "    # Run baseline evaluation (fresh or resumed)\n",
    "    print(f\"\\nüöÄ Running {MODEL_NAME} baseline evaluation...\")\n",
    "    print(f\"   Format: {PROMPT_FORMAT}\")\n",
    "    print(f\"   Samples: {len(test_samples)}\")\n",
    "    print(f\"   Checkpoint: {GENERATION_CHECKPOINT_PATH}\")\n",
    "    \n",
    "    # Record start time for duration tracking\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Clear GPU memory before loading model\n",
    "    clear_memory()\n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = load_model_for_inference(MODEL_NAME)\n",
    "    \n",
    "    # Generate predictions for all test samples (with checkpointing)\n",
    "    predictions = generate_predictions(\n",
    "        model=model,  # Loaded model\n",
    "        tokenizer=tokenizer,  # Loaded tokenizer\n",
    "        test_samples=test_samples,  # Test data\n",
    "        prompt_format=PROMPT_FORMAT,  # Mistral format\n",
    "        max_new_tokens=MAX_NEW_TOKENS,  # Generation limit\n",
    "        checkpoint_path=GENERATION_CHECKPOINT_PATH,  # Intermediate checkpoint path\n",
    "        save_every=100  # Save every 100 samples\n",
    "    )\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    print(f\"\\nüìä Computing metrics...\")\n",
    "    metrics = compute_metrics(\n",
    "        predictions=[p[\"prediction\"] for p in predictions],  # Extract predictions\n",
    "        references=[p[\"reference\"] for p in predictions],  # Extract references\n",
    "        sources=[p[\"complex_text\"] for p in predictions],  # Extract sources\n",
    "        compute_bertscore=True  # Include BERTScore\n",
    "    )\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed = time.time() - start_time\n",
    "    # Add timing to metrics\n",
    "    metrics[\"elapsed_time\"] = elapsed\n",
    "    \n",
    "    # Store results in global dictionaries\n",
    "    baseline_results[MODEL_NAME] = metrics\n",
    "    baseline_predictions[MODEL_NAME] = predictions\n",
    "    \n",
    "    # Save final checkpoint for recovery (per-model file)\n",
    "    save_baseline_checkpoint(MODEL_NAME, predictions, metrics)\n",
    "    \n",
    "    # Remove intermediate generation checkpoint (no longer needed)\n",
    "    if GENERATION_CHECKPOINT_PATH.exists():\n",
    "        GENERATION_CHECKPOINT_PATH.unlink()  # Delete the file\n",
    "        print(f\"   ‚úì Removed intermediate checkpoint\")\n",
    "    \n",
    "    # Print results summary\n",
    "    print(f\"\\nüìä {MODEL_NAME} Baseline Results:\")\n",
    "    print(f\"   ROUGE-L: {metrics['ROUGE-L']:.4f}\")\n",
    "    print(f\"   SARI: {metrics['SARI']:.2f}\")\n",
    "    print(f\"   BERTScore-F1: {metrics['BERTScore-F1']:.4f}\")\n",
    "    print(f\"   FK-Grade: {metrics['FK-Grade-Mean']:.2f} (¬±{metrics['FK-Grade-Std']:.2f})\")\n",
    "    print(f\"   Valid samples: {metrics['valid_samples']}/{metrics['total_samples']}\")\n",
    "    print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Clean up: delete model and tokenizer to free memory\n",
    "    del model, tokenizer\n",
    "    # Clear GPU memory\n",
    "    clear_memory()\n",
    "\n",
    "# Print section completion message\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SECTION 5.9.3 COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.10: Baseline Results Aggregation\n",
    "\n",
    "Aggregate and visualize baseline results. Answer RQ1 and RQ2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SECTION 5.10: BASELINE RESULTS AGGREGATION\n",
      "======================================================================\n",
      "\n",
      "üìä Baseline Results Summary:\n",
      "             Model    Type  Format  ROUGE-L      SARI  BERTScore-F1  FK-Grade   FK-Std  Valid  Total\n",
      "     OpenBioLLM-8B Medical  chatml 0.262339 36.982421      0.637070 12.526028 3.699005   1001   1001\n",
      "BioMistral-7B-DARE Medical mistral 0.411992 51.914132      0.742610  9.517294 3.560177   1001   1001\n",
      "        Mistral-7B General mistral 0.391178 46.379447      0.733548 10.604462 8.317927   1001   1001\n",
      "\n",
      "üìÅ Saving results...\n",
      "   ‚úì Saved: /workspace/medisimplifier/results/baseline/baseline_metrics.csv\n",
      "   ‚úì Saved: /workspace/medisimplifier/results/baseline/baseline_results.json\n",
      "\n",
      "üìà Creating visualizations...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Saved: /workspace/medisimplifier/results/figures/baseline_comparison.png\n",
      "\n",
      "======================================================================\n",
      "RESEARCH QUESTIONS ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìã RQ1: Does medical pretraining help zero-shot simplification?\n",
      "   Medical models avg ROUGE-L: 0.3372\n",
      "   General models avg ROUGE-L: 0.3912\n",
      "   Medical models avg SARI: 44.45\n",
      "   General models avg SARI: 46.38\n",
      "   ‚Üí Answer: NO - General model outperforms medical models by 16.0% on ROUGE-L.\n",
      "\n",
      "üìã RQ2: Which model is best at zero-shot?\n",
      "   Ranking by ROUGE-L:\n",
      "      1. BioMistral-7B-DARE: ROUGE-L=0.4120, SARI=51.91\n",
      "      2. Mistral-7B: ROUGE-L=0.3912, SARI=46.38\n",
      "      3. OpenBioLLM-8B: ROUGE-L=0.2623, SARI=36.98\n",
      "   ‚Üí Answer: BioMistral-7B-DARE (ROUGE-L=0.4120, SARI=51.91, FK=9.52)\n",
      "\n",
      "üìÅ Saved: /workspace/medisimplifier/results/baseline/baseline_summary.md\n",
      "\n",
      "======================================================================\n",
      "CHAPTER 5 COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   - instruction_dataset/chatml/ (ChatML format dataset)\n",
      "   - instruction_dataset/mistral/ (Mistral format dataset)\n",
      "   - baseline_metrics.csv\n",
      "   - baseline_results.json\n",
      "   - baseline_summary.md\n",
      "   - figures/baseline_comparison.png\n",
      "   - baseline_openbiollm_8b.json\n",
      "   - baseline_biomistral_7b_dare.json\n",
      "   - baseline_mistral_7b.json\n",
      "\n",
      "üìä Baseline Summary:\n",
      "   Best Zero-Shot: BioMistral-7B-DARE\n",
      "   - ROUGE-L: 0.4120\n",
      "   - SARI: 51.91\n",
      "   - FK-Grade: 9.52\n",
      "\n",
      "‚û°Ô∏è Proceed to Chapter 6 for LoRA Fine-Tuning\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.10: BASELINE RESULTS AGGREGATION\n",
    "# =============================================================================\n",
    "\n",
    "# Print section header for logging\n",
    "print(\"=\" * 70)\n",
    "print(\"SECTION 5.10: BASELINE RESULTS AGGREGATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create Results DataFrame\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print summary header\n",
    "print(f\"\\nüìä Baseline Results Summary:\")\n",
    "\n",
    "# Build list of result dictionaries for DataFrame creation\n",
    "results_data = []\n",
    "# Iterate through models in evaluation order\n",
    "for model_name in BASELINE_EVAL_ORDER:\n",
    "    # Check if results exist for this model\n",
    "    if model_name in baseline_results:\n",
    "        # Get metrics for current model\n",
    "        metrics = baseline_results[model_name]\n",
    "        # Get configuration for current model\n",
    "        config = STUDENT_MODELS[model_name]\n",
    "        # Append result dictionary with all relevant fields\n",
    "        results_data.append({\n",
    "            \"Model\": model_name,  # Model name\n",
    "            \"Type\": config[\"type\"],  # Medical or General\n",
    "            \"Format\": config[\"prompt_format\"],  # chatml or mistral\n",
    "            \"ROUGE-L\": metrics[\"ROUGE-L\"],  # ROUGE-L score\n",
    "            \"SARI\": metrics[\"SARI\"],  # SARI score\n",
    "            \"BERTScore-F1\": metrics.get(\"BERTScore-F1\", None),  # BERTScore (may be None)\n",
    "            \"FK-Grade\": metrics[\"FK-Grade-Mean\"],  # Mean Flesch-Kincaid grade\n",
    "            \"FK-Std\": metrics[\"FK-Grade-Std\"],  # FK standard deviation\n",
    "            \"Valid\": metrics[\"valid_samples\"],  # Count of valid predictions\n",
    "            \"Total\": metrics[\"total_samples\"],  # Total samples attempted\n",
    "        })\n",
    "\n",
    "# Create pandas DataFrame from results list\n",
    "baseline_df = pd.DataFrame(results_data)\n",
    "# Print DataFrame as formatted string\n",
    "print(baseline_df.to_string(index=False))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Save Results\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print save status\n",
    "print(f\"\\nüìÅ Saving results...\")\n",
    "\n",
    "# Define path for CSV file\n",
    "csv_path = BASELINE_DIR / \"baseline_metrics.csv\"\n",
    "# Save DataFrame to CSV\n",
    "baseline_df.to_csv(csv_path, index=False)\n",
    "# Print confirmation\n",
    "print(f\"   ‚úì Saved: {csv_path}\")\n",
    "\n",
    "# Define path for JSON results file\n",
    "json_path = BASELINE_DIR / \"baseline_results.json\"\n",
    "# Save detailed results to JSON\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"results\": baseline_results,  # Full metrics dictionary\n",
    "        \"reference_stats\": REFERENCE_STATS,  # Reference statistics\n",
    "        \"timestamp\": datetime.now().isoformat(),  # Save timestamp\n",
    "    }, f, indent=2)\n",
    "# Print confirmation\n",
    "print(f\"   ‚úì Saved: {json_path}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Visualization\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print visualization status\n",
    "print(f\"\\nüìà Creating visualizations...\")\n",
    "\n",
    "# Create 2x2 subplot figure for metrics comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "# Define colors for each model (green, blue, red)\n",
    "colors = [\"#2ecc71\", \"#3498db\", \"#e74c3c\"]\n",
    "\n",
    "# Plot 1: ROUGE-L scores (top-left)\n",
    "ax = axes[0, 0]\n",
    "# Create bar chart for ROUGE-L\n",
    "bars = ax.bar(baseline_df[\"Model\"], baseline_df[\"ROUGE-L\"], color=colors)\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"ROUGE-L\")\n",
    "# Set chart title\n",
    "ax.set_title(\"Zero-Shot ROUGE-L Scores\")\n",
    "# Set y-axis limit with 20% headroom\n",
    "ax.set_ylim(0, max(baseline_df[\"ROUGE-L\"]) * 1.2)\n",
    "# Add value labels on top of each bar\n",
    "for bar, val in zip(bars, baseline_df[\"ROUGE-L\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f\"{val:.3f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Plot 2: SARI scores (top-right)\n",
    "ax = axes[0, 1]\n",
    "# Create bar chart for SARI\n",
    "bars = ax.bar(baseline_df[\"Model\"], baseline_df[\"SARI\"], color=colors)\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"SARI\")\n",
    "# Set chart title\n",
    "ax.set_title(\"Zero-Shot SARI Scores\")\n",
    "# Add target line at SARI=40 (good simplification threshold)\n",
    "ax.axhline(y=40, color=\"gray\", linestyle=\"--\", label=\"Target (‚â•40)\")\n",
    "# Add legend\n",
    "ax.legend()\n",
    "# Add value labels on top of each bar\n",
    "for bar, val in zip(bars, baseline_df[\"SARI\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f\"{val:.1f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Plot 3: FK-Grade scores (bottom-left)\n",
    "ax = axes[1, 0]\n",
    "# Create bar chart for FK Grade\n",
    "bars = ax.bar(baseline_df[\"Model\"], baseline_df[\"FK-Grade\"], color=colors)\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"FK Grade Level\")\n",
    "# Set chart title\n",
    "ax.set_title(\"Zero-Shot Flesch-Kincaid Grade\")\n",
    "# Add target line at FK=6 (6th grade target)\n",
    "ax.axhline(y=6, color=\"green\", linestyle=\"--\", label=\"Target (‚â§6)\")\n",
    "# Add reference line showing ground truth mean FK\n",
    "ax.axhline(y=REFERENCE_STATS[\"fk_mean\"], color=\"orange\", linestyle=\"--\", \n",
    "           label=f\"Reference ({REFERENCE_STATS['fk_mean']:.1f})\")\n",
    "# Add legend\n",
    "ax.legend()\n",
    "# Add value labels on top of each bar\n",
    "for bar, val in zip(bars, baseline_df[\"FK-Grade\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, \n",
    "            f\"{val:.1f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Plot 4: BERTScore F1 (bottom-right)\n",
    "ax = axes[1, 1]\n",
    "# Handle potential None values in BERTScore by filling with 0\n",
    "bertscore_vals = baseline_df[\"BERTScore-F1\"].fillna(0)\n",
    "# Create bar chart for BERTScore\n",
    "bars = ax.bar(baseline_df[\"Model\"], bertscore_vals, color=colors)\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\"BERTScore F1\")\n",
    "# Set chart title\n",
    "ax.set_title(\"Zero-Shot BERTScore F1\")\n",
    "# Set y-axis limit with 20% headroom, minimum of 1 if all zeros\n",
    "ax.set_ylim(0, max(bertscore_vals) * 1.2 if max(bertscore_vals) > 0 else 1)\n",
    "# Add value labels on top of each bar (only if non-zero)\n",
    "for bar, val in zip(bars, bertscore_vals):\n",
    "    if val > 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f\"{val:.3f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "# Define save path for figure\n",
    "fig_path = FIGURES_DIR / \"baseline_comparison.png\"\n",
    "# Save figure to file\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "# Display figure\n",
    "plt.show()\n",
    "# Print confirmation\n",
    "print(f\"   ‚úì Saved: {fig_path}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Research Questions Analysis\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print RQ analysis header\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"RESEARCH QUESTIONS ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Identify medical vs general models for comparison\n",
    "# Get list of medical model names\n",
    "medical_models = [m for m in BASELINE_EVAL_ORDER if STUDENT_MODELS[m][\"type\"] == \"Medical\"]\n",
    "# Get list of general model names\n",
    "general_models = [m for m in BASELINE_EVAL_ORDER if STUDENT_MODELS[m][\"type\"] == \"General\"]\n",
    "\n",
    "# RQ1: Does medical pretraining help zero-shot simplification?\n",
    "print(f\"\\nüìã RQ1: Does medical pretraining help zero-shot simplification?\")\n",
    "\n",
    "# Calculate average ROUGE-L for medical models\n",
    "medical_avg_rouge = np.mean([baseline_results[m][\"ROUGE-L\"] for m in medical_models])\n",
    "# Calculate average ROUGE-L for general models\n",
    "general_avg_rouge = np.mean([baseline_results[m][\"ROUGE-L\"] for m in general_models])\n",
    "\n",
    "# Calculate average SARI for medical models\n",
    "medical_avg_sari = np.mean([baseline_results[m][\"SARI\"] for m in medical_models])\n",
    "# Calculate average SARI for general models\n",
    "general_avg_sari = np.mean([baseline_results[m][\"SARI\"] for m in general_models])\n",
    "\n",
    "# Print comparison statistics\n",
    "print(f\"   Medical models avg ROUGE-L: {medical_avg_rouge:.4f}\")\n",
    "print(f\"   General models avg ROUGE-L: {general_avg_rouge:.4f}\")\n",
    "print(f\"   Medical models avg SARI: {medical_avg_sari:.2f}\")\n",
    "print(f\"   General models avg SARI: {general_avg_sari:.2f}\")\n",
    "\n",
    "# Determine answer based on comparison\n",
    "if medical_avg_rouge > general_avg_rouge:\n",
    "    # Medical models performed better\n",
    "    rq1_answer = f\"YES - Medical pretraining helps. Medical models outperform general by {(medical_avg_rouge - general_avg_rouge)/general_avg_rouge*100:.1f}% on ROUGE-L.\"\n",
    "else:\n",
    "    # General models performed better\n",
    "    rq1_answer = f\"NO - General model outperforms medical models by {(general_avg_rouge - medical_avg_rouge)/medical_avg_rouge*100:.1f}% on ROUGE-L.\"\n",
    "# Print RQ1 answer\n",
    "print(f\"   ‚Üí Answer: {rq1_answer}\")\n",
    "\n",
    "# RQ2: Which model is best at zero-shot?\n",
    "print(f\"\\nüìã RQ2: Which model is best at zero-shot?\")\n",
    "\n",
    "# Rank models by ROUGE-L score (descending)\n",
    "ranked_models = sorted(\n",
    "    baseline_results.keys(),  # All evaluated models\n",
    "    key=lambda m: baseline_results[m][\"ROUGE-L\"],  # Sort by ROUGE-L\n",
    "    reverse=True  # Highest first\n",
    ")\n",
    "\n",
    "# Get best model (first in ranked list)\n",
    "best_model = ranked_models[0]\n",
    "# Get metrics for best model\n",
    "best_metrics = baseline_results[best_model]\n",
    "\n",
    "# Print ranking\n",
    "print(f\"   Ranking by ROUGE-L:\")\n",
    "for i, model in enumerate(ranked_models, 1):\n",
    "    print(f\"      {i}. {model}: ROUGE-L={baseline_results[model]['ROUGE-L']:.4f}, SARI={baseline_results[model]['SARI']:.2f}\")\n",
    "\n",
    "# Format RQ2 answer\n",
    "rq2_answer = f\"{best_model} (ROUGE-L={best_metrics['ROUGE-L']:.4f}, SARI={best_metrics['SARI']:.2f}, FK={best_metrics['FK-Grade-Mean']:.2f})\"\n",
    "# Print RQ2 answer\n",
    "print(f\"   ‚Üí Answer: {rq2_answer}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Generate Summary Report\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Create markdown summary report\n",
    "summary_md = f\"\"\"# MediSimplifier Baseline Summary\n",
    "\n",
    "**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Zero-Shot Baseline Results\n",
    "\n",
    "| Model | Type | ROUGE-L | SARI | BERTScore | FK-Grade |\n",
    "|-------|------|---------|------|-----------|----------|\n",
    "\"\"\"\n",
    "\n",
    "# Add row for each model\n",
    "for _, row in baseline_df.iterrows():\n",
    "    # Format BERTScore (handle None)\n",
    "    bertscore = f\"{row['BERTScore-F1']:.4f}\" if pd.notna(row['BERTScore-F1']) else \"N/A\"\n",
    "    # Add table row\n",
    "    summary_md += f\"| {row['Model']} | {row['Type']} | {row['ROUGE-L']:.4f} | {row['SARI']:.2f} | {bertscore} | {row['FK-Grade']:.2f} |\\n\"\n",
    "\n",
    "# Add reference statistics and RQ answers\n",
    "summary_md += f\"\"\"\n",
    "## Reference Statistics (Ground Truth)\n",
    "\n",
    "- FK Grade Mean: {REFERENCE_STATS['fk_mean']:.2f}\n",
    "- FK Grade Std: {REFERENCE_STATS['fk_std']:.2f}\n",
    "- Total Samples: {REFERENCE_STATS['n_samples']}\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "### RQ1: Does medical pretraining help zero-shot simplification?\n",
    "\n",
    "{rq1_answer}\n",
    "\n",
    "### RQ2: Which model is best at zero-shot?\n",
    "\n",
    "{rq2_answer}\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. Best zero-shot model: **{best_model}**\n",
    "2. All models produce text above target FK grade (‚â§6)\n",
    "3. SARI scores indicate {'adequate' if best_metrics['SARI'] >= 40 else 'inadequate'} simplification quality\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Proceed to Chapter 6 for LoRA fine-tuning\n",
    "- Use these baselines to measure improvement from training\n",
    "\"\"\"\n",
    "\n",
    "# Define save path for summary markdown\n",
    "summary_path = BASELINE_DIR / \"baseline_summary.md\"\n",
    "# Save summary to file\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_md)\n",
    "# Print confirmation\n",
    "print(f\"\\nüìÅ Saved: {summary_path}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Final Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Print chapter completion header\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"CHAPTER 5 COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# List all generated files\n",
    "print(f\"\\nüìÅ Generated Files:\")\n",
    "print(f\"   - instruction_dataset/chatml/ (ChatML format dataset)\")\n",
    "print(f\"   - instruction_dataset/mistral/ (Mistral format dataset)\")\n",
    "print(f\"   - baseline_metrics.csv\")\n",
    "print(f\"   - baseline_results.json\")\n",
    "print(f\"   - baseline_summary.md\")\n",
    "print(f\"   - figures/baseline_comparison.png\")\n",
    "# List individual model prediction files\n",
    "for model_name in BASELINE_EVAL_ORDER:\n",
    "    print(f\"   - baseline_{model_name.lower().replace('-', '_')}.json\")\n",
    "\n",
    "# Print summary of best model\n",
    "print(f\"\\nüìä Baseline Summary:\")\n",
    "print(f\"   Best Zero-Shot: {best_model}\")\n",
    "print(f\"   - ROUGE-L: {best_metrics['ROUGE-L']:.4f}\")\n",
    "print(f\"   - SARI: {best_metrics['SARI']:.2f}\")\n",
    "print(f\"   - FK-Grade: {best_metrics['FK-Grade-Mean']:.2f}\")\n",
    "\n",
    "# Print next steps\n",
    "print(f\"\\n‚û°Ô∏è Proceed to Chapter 6 for LoRA Fine-Tuning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
