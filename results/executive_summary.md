# MediSimplifier: Executive Summary

## Project Overview
**Course:** Technion DS25 Deep Learning  
**Team:** Guy Dor, Shmulik Avraham  
**Objective:** Simplify medical discharge summaries to 6th-grade reading level using LoRA fine-tuning

---

## Key Results

### Best Performing Model (Fine-Tuned)
| Metric | OpenBioLLM-8B | Target |
|--------|---------------|--------|
| ROUGE-L | **0.6749** | Higher |
| SARI | **74.64** | ≥40 ✅ |
| BERTScore-F1 | **0.9498** | Higher |
| FK-Grade | **7.16** | ≤6 (close) |

### Improvement Over Baseline
| Model | Baseline ROUGE-L | Fine-Tuned ROUGE-L | Improvement |
|-------|------------------|--------------------| ------------|
| **OpenBioLLM-8B** | 0.2623 | **0.6749** | **+157.3%** |
| Mistral-7B | 0.3912 | 0.6491 | +65.9% |
| BioMistral-7B-DARE | 0.4120 | 0.6318 | +53.3% |

### Readability Achievement
- **Source text:** FK-Grade 14.50 (College level)
- **Ground truth:** FK-Grade 7.23 (7th grade)
- **Best model:** FK-Grade 6.91 (Mistral-7B)
- **Reduction achieved:** ~50%

---

## Optimal LoRA Configuration
```python
LoraConfig(
    r=32,                    # Phase 1: Higher rank = better
    lora_alpha=64,           # α = 2×r
    target_modules=[         # Phase 2: all_attn optimal
        "q_proj", "k_proj", 
        "v_proj", "o_proj"
    ],
    use_rslora=True,         # Literature-based decision
    lora_dropout=0.05,
)
```
**Trainable Parameters:** 27.3M (0.38% of base model)

---

## Key Research Findings

### 1. Ranking Reversal (RQ5)
- **Zero-shot ranking:** BioMistral > Mistral > OpenBioLLM
- **Fine-tuned ranking:** OpenBioLLM > Mistral > BioMistral (reversed!)
- **Insight:** Worst baseline achieved largest improvement (+157%)

### 2. Medical Pretraining (RQ1, RQ5)
- Medical pretraining advantage **disappears** after task-specific fine-tuning
- General architecture learning capacity matters more than domain pretraining

### 3. Ablation Study Contributions
- **Contradicts Hu et al. (2021):** r=32 outperforms r=4-8
- **Confirms Raschka (2023):** all_attn modules optimal
- **Standard ML scaling:** More data consistently improves results

### 4. Data Efficiency (RQ7)
- 4K samples achieve 97% of full 8K performance
- Diminishing returns above 4K samples

---

## Figures Generated
1. `project_overview_dashboard.png` - 4-panel project summary
2. `ablation_study_summary.png` - 3-panel ablation results
3. `research_questions_summary.png` - RQ infographic
4. `model_performance_heatmap.png` - Multi-metric comparison
5. `rq8_correlation_plot.png` - Baseline vs improvement correlation

---

## Resource Usage
| Resource | Value |
|----------|-------|
| Training Hardware | RunPod H200 SXM (3 GPUs) |
| Total GPU Time | ~7.5 hours (parallel) |
| Ablation Runs | 18 configurations |
| Full Training Runs | 3 models × 3 epochs |
| Test Samples | 1,001 |
| Total Storage | ~3.4 GB |

---

## Conclusions

1. **LoRA fine-tuning is highly effective** for medical text simplification (+53% to +157% improvement)

2. **OpenBioLLM-8B recommended** for production deployment (best quality on 3/4 metrics)

3. **Medical pretraining not required** - task-specific fine-tuning overcomes zero-shot limitations

4. **Optimal LoRA config:** r=32, all_attn, rsLoRA=True (contradicts some original LoRA recommendations)

5. **50% readability reduction achieved** - college level (14.5) to 7th grade (~7.0)

---

## Files & Artifacts
- **Notebooks:** 4 parts (Part 1-4)
- **LoRA Adapters:** 3 models (109 MB each)
- **Checkpoints:** 9 (3 models × 3 epochs)
- **Results JSON:** 7 evaluation files
- **Figures:** 17 PNG visualizations

---

*Generated by MediSimplifier Section 8.3*
